{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":12355137,"sourceType":"datasetVersion","datasetId":7789382}],"dockerImageVersionId":31041,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# ================================================\n# ‚úÖ 1Ô∏è‚É£ LIBRARIES & SETUP\n# ================================================\nimport os\nimport pandas as pd\nimport torch\nfrom torch.utils.data import Dataset, DataLoader\nfrom transformers import AutoTokenizer, AutoModel\nfrom torch.optim import AdamW\nfrom tqdm import tqdm\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score, precision_recall_fscore_support, confusion_matrix\nimport re\nimport string\n\n# ================================================\n# ‚úÖ 2Ô∏è‚É£ PATHS\n# ================================================\ninput_csv = \"/kaggle/input/basem/dataset.csv\"\n\n# ================================================\n# ‚úÖ 3Ô∏è‚É£ LOAD & PREPROCESS CSV\n# ================================================\ndf = pd.read_csv(input_csv)\n\nexisting_data = []\nfor _, row in df.iterrows():\n    # Only check if text exists (no image path checking needed)\n    if pd.notna(row['extracted_text']) and row['extracted_text'].strip():\n        label_converted = row['label 2'] - 1\n        existing_data.append({\n            'Captions': row['extracted_text'],\n            'Label_Sentiment': label_converted\n        })\n\nprocessed_df = pd.DataFrame(existing_data)\n\n# ================================================\n# ‚úÖ 4Ô∏è‚É£ TEXT CLEANING\n# ================================================\ndef clean_text(text):\n    if pd.isna(text): return \"\"\n    text = re.sub(r'https?://\\S+|www\\.\\S+', '', text)\n    text = re.sub(r'<.*?>', '', text)\n    text = text.translate(str.maketrans('', '', string.punctuation))\n    text = \" \".join(text.split())\n    return text\n\ntrain_df, temp_df = train_test_split(processed_df, test_size=0.3, stratify=processed_df['Label_Sentiment'], random_state=42)\ntest_df, val_df = train_test_split(temp_df, test_size=1/3, stratify=temp_df['Label_Sentiment'], random_state=42)\n\nfor df_name, df_ in [('train', train_df), ('test', test_df), ('val', val_df)]:\n    df_['Captions'] = df_['Captions'].astype(str).apply(clean_text)\n    df_['label'] = df_['Label_Sentiment']\n    df_.to_csv(f'/kaggle/working/{df_name}_cleaned.csv', index=False)\n\n# ================================================\n# ‚úÖ 5Ô∏è‚É£ LOAD MuRIL MODEL\n# ================================================\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nprint(f\"Using device: {device}\")\n\n# Load MuRIL tokenizer and model\ntokenizer = AutoTokenizer.from_pretrained(\"google/muril-base-cased\")\nmuril_model = AutoModel.from_pretrained(\"google/muril-base-cased\").to(device)\n\n# ================================================\n# ‚úÖ 6Ô∏è‚É£ TEXT-ONLY DATASET\n# ================================================\nclass TextOnlyDataset(Dataset):\n    def __init__(self, df, tokenizer, max_length=128):\n        self.df = df\n        self.tokenizer = tokenizer\n        self.max_length = max_length\n\n    def __len__(self):\n        return len(self.df)\n\n    def __getitem__(self, idx):\n        row = self.df.iloc[idx]\n        text = row['Captions']\n        label = row['label']\n        \n        # Tokenize text\n        encoded = self.tokenizer(\n            text,\n            truncation=True,\n            padding='max_length',\n            max_length=self.max_length,\n            return_tensors='pt'\n        )\n        \n        return {\n            'input_ids': encoded['input_ids'].flatten(),\n            'attention_mask': encoded['attention_mask'].flatten(),\n            'label': torch.tensor(label, dtype=torch.long)\n        }\n\n# ================================================\n# ‚úÖ 7Ô∏è‚É£ DATALOADERS\n# ================================================\nbatch_size = 16\n\ntrain_dataset = TextOnlyDataset(train_df, tokenizer)\nval_dataset = TextOnlyDataset(val_df, tokenizer)\ntest_dataset = TextOnlyDataset(test_df, tokenizer)\n\ntrain_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\nval_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\ntest_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n\n# ================================================\n# ‚úÖ 8Ô∏è‚É£ TEXT CLASSIFICATION MODEL\n# ================================================\nclass MuRILClassifier(torch.nn.Module):\n    def __init__(self, muril_model, num_classes=3, dropout=0.3):\n        super().__init__()\n        self.muril = muril_model\n        self.dropout = torch.nn.Dropout(dropout)\n        self.classifier = torch.nn.Linear(muril_model.config.hidden_size, num_classes)\n        \n    def forward(self, input_ids, attention_mask):\n        outputs = self.muril(\n            input_ids=input_ids,\n            attention_mask=attention_mask\n        )\n        \n        # Use [CLS] token representation\n        pooled_output = outputs.last_hidden_state[:, 0, :]\n        pooled_output = self.dropout(pooled_output)\n        logits = self.classifier(pooled_output)\n        \n        return logits\n\n# ================================================\n# ‚úÖ 9Ô∏è‚É£ INITIALIZE MODEL\n# ================================================\nmodel = MuRILClassifier(muril_model, num_classes=3).to(device)\n\n# ================================================\n# ‚úÖ üîü LOSS & OPTIMIZER\n# ================================================\n# Calculate class weights for imbalanced dataset\nclass_weights = train_df['label'].value_counts().sort_index().tolist()\ntotal = sum(class_weights)\nweights = [total / c for c in class_weights]\ncriterion = torch.nn.CrossEntropyLoss(weight=torch.FloatTensor(weights).to(device))\noptimizer = AdamW(model.parameters(), lr=2e-5)\n\nprint(f\"Class distribution: {class_weights}\")\nprint(f\"Class weights: {weights}\")\n\n# ================================================\n# ‚úÖ 1Ô∏è‚É£1Ô∏è‚É£ TRAINING LOOP\n# ================================================\nnum_epochs = 20\npatience = 5\npatience_counter = 0\nbest_val_loss = float('inf')\n\nfor epoch in range(num_epochs):\n    # ============================================================\n    # TRAINING PHASE\n    # ============================================================\n    model.train()\n    total_train_loss = 0\n    train_predictions = []\n    train_labels = []\n\n    for batch in tqdm(train_loader, desc=f\"Train Epoch {epoch+1}\"):\n        input_ids = batch['input_ids'].to(device)\n        attention_mask = batch['attention_mask'].to(device)\n        labels = batch['label'].to(device)\n\n        optimizer.zero_grad()\n        \n        logits = model(input_ids, attention_mask)\n        loss = criterion(logits, labels)\n        \n        loss.backward()\n        optimizer.step()\n        \n        total_train_loss += loss.item()\n        \n        # Store predictions for metrics\n        predictions = torch.argmax(logits, dim=1)\n        train_predictions.extend(predictions.cpu().numpy())\n        train_labels.extend(labels.cpu().numpy())\n\n    avg_train_loss = total_train_loss / len(train_loader)\n    train_accuracy = accuracy_score(train_labels, train_predictions)\n\n    # ============================================================\n    # VALIDATION PHASE\n    # ============================================================\n    model.eval()\n    total_val_loss = 0\n    val_predictions = []\n    val_labels = []\n\n    with torch.no_grad():\n        for batch in tqdm(val_loader, desc=f\"Validation Epoch {epoch+1}\"):\n            input_ids = batch['input_ids'].to(device)\n            attention_mask = batch['attention_mask'].to(device)\n            labels = batch['label'].to(device)\n\n            logits = model(input_ids, attention_mask)\n            loss = criterion(logits, labels)\n\n            total_val_loss += loss.item()\n            \n            # Store predictions for metrics\n            predictions = torch.argmax(logits, dim=1)\n            val_predictions.extend(predictions.cpu().numpy())\n            val_labels.extend(labels.cpu().numpy())\n\n    avg_val_loss = total_val_loss / len(val_loader)\n    val_accuracy = accuracy_score(val_labels, val_predictions)\n    \n    print(f\"Epoch [{epoch+1}/{num_epochs}]\")\n    print(f\"Train Loss: {avg_train_loss:.4f} | Train Acc: {train_accuracy:.4f}\")\n    print(f\"Val Loss: {avg_val_loss:.4f} | Val Acc: {val_accuracy:.4f}\")\n\n    # ============================================================\n    # EARLY STOPPING CHECK\n    # ============================================================\n    if avg_val_loss < best_val_loss:\n        best_val_loss = avg_val_loss\n        patience_counter = 0\n        torch.save(model.state_dict(), \"best_muril_model.pt\")\n        print(\"‚úÖ Validation loss improved ‚Äî model saved.\")\n    else:\n        patience_counter += 1\n        print(f\"‚è∞ No improvement ‚Äî patience {patience_counter}/{patience}\")\n\n        if patience_counter >= patience:\n            print(f\"üõë Early stopping triggered at epoch {epoch+1}\")\n            break\n    \n    print(\"-\" * 50)\n\n# ================================================\n# ‚úÖ 1Ô∏è‚É£2Ô∏è‚É£ FINAL TEST EVALUATION\n# ================================================\nprint(\"\\nüîç Loading best model for final evaluation...\")\nmodel.load_state_dict(torch.load(\"best_muril_model.pt\"))\nmodel.eval()\n\ntest_predictions = []\ntest_labels = []\ntotal_test_loss = 0\n\nwith torch.no_grad():\n    for batch in tqdm(test_loader, desc=\"Final Test Evaluation\"):\n        input_ids = batch['input_ids'].to(device)\n        attention_mask = batch['attention_mask'].to(device)\n        labels = batch['label'].to(device)\n\n        logits = model(input_ids, attention_mask)\n        loss = criterion(logits, labels)\n        \n        total_test_loss += loss.item()\n        predictions = torch.argmax(logits, dim=1)\n        test_predictions.extend(predictions.cpu().numpy())\n        test_labels.extend(labels.cpu().numpy())\n\n# Calculate final metrics\ntest_accuracy = accuracy_score(test_labels, test_predictions)\nprecision, recall, f1, _ = precision_recall_fscore_support(test_labels, test_predictions, average='weighted')\ncm = confusion_matrix(test_labels, test_predictions)\n\nprint(\"\\nüìä FINAL TEST RESULTS (TEXT-ONLY WITH MuRIL):\")\nprint(\"=\" * 60)\nprint(f\"Test Accuracy: {test_accuracy:.4f}\")\nprint(f\"Test Precision (Weighted): {precision:.4f}\")\nprint(f\"Test Recall (Weighted): {recall:.4f}\")\nprint(f\"Test F1-Score (Weighted): {f1:.4f}\")\nprint(f\"Test Loss: {total_test_loss/len(test_loader):.4f}\")\nprint(f\"\\nConfusion Matrix:\\n{cm}\")\n\n# ================================================\n# ‚úÖ 1Ô∏è‚É£3Ô∏è‚É£ DETAILED METRICS BY CLASS\n# ================================================\nprecision_per_class, recall_per_class, f1_per_class, support = precision_recall_fscore_support(\n    test_labels, test_predictions, average=None\n)\n\nprint(\"\\nüìã PER-CLASS METRICS:\")\nprint(\"=\" * 40)\nclass_names = ['Class 0', 'Class 1', 'Class 2']\nfor i, class_name in enumerate(class_names):\n    print(f\"{class_name}:\")\n    print(f\"  Precision: {precision_per_class[i]:.4f}\")\n    print(f\"  Recall: {recall_per_class[i]:.4f}\")\n    print(f\"  F1-Score: {f1_per_class[i]:.4f}\")\n    print(f\"  Support: {support[i]}\")\n    print()\n\nprint(f\"Total samples: {len(test_labels)}\")\nprint(f\"Dataset size - Train: {len(train_df)}, Val: {len(val_df)}, Test: {len(test_df)}\")","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-07-07T07:44:09.710581Z","iopub.execute_input":"2025-07-07T07:44:09.711405Z","iopub.status.idle":"2025-07-07T08:00:28.988063Z","shell.execute_reply.started":"2025-07-07T07:44:09.711376Z","shell.execute_reply":"2025-07-07T08:00:28.987261Z"}},"outputs":[{"name":"stdout","text":"Using device: cuda\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/206 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7c479efd450a42fb9182b1e9d7eeb1f4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/411 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a214ffa50b4d46b582cfeaa0d9fed0af"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e0aee74ea2b543be92bd5e0f53c0e529"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/113 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5aa33df687e6489d9cf8751e705175d8"}},"metadata":{}},{"name":"stderr","text":"2025-07-07 07:44:29.913573: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1751874270.099258      35 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1751874270.154104      35 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin:   0%|          | 0.00/953M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ed758f2d06e84ab0bba76233805e4a72"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/953M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d3632c46b82e488ab179eb7c49951132"}},"metadata":{}},{"name":"stdout","text":"Class distribution: [1404, 1237, 515]\nClass weights: [2.247863247863248, 2.551333872271625, 6.128155339805825]\n","output_type":"stream"},{"name":"stderr","text":"\nTrain Epoch 1:   0%|          | 0/198 [00:00<?, ?it/s]\u001b[A\nTrain Epoch 1:   1%|          | 1/198 [00:00<02:20,  1.40it/s]\u001b[A\nTrain Epoch 1:   1%|          | 2/198 [00:00<01:24,  2.32it/s]\u001b[A\nTrain Epoch 1:   2%|‚ñè         | 3/198 [00:01<01:05,  2.96it/s]\u001b[A\nTrain Epoch 1:   2%|‚ñè         | 4/198 [00:01<00:57,  3.39it/s]\u001b[A\nTrain Epoch 1:   3%|‚ñé         | 5/198 [00:01<00:52,  3.67it/s]\u001b[A\nTrain Epoch 1:   3%|‚ñé         | 6/198 [00:01<00:49,  3.88it/s]\u001b[A\nTrain Epoch 1:   4%|‚ñé         | 7/198 [00:02<00:47,  4.02it/s]\u001b[A\nTrain Epoch 1:   4%|‚ñç         | 8/198 [00:02<00:46,  4.12it/s]\u001b[A\nTrain Epoch 1:   5%|‚ñç         | 9/198 [00:02<00:45,  4.18it/s]\u001b[A\nTrain Epoch 1:   5%|‚ñå         | 10/198 [00:02<00:44,  4.23it/s]\u001b[A\nTrain Epoch 1:   6%|‚ñå         | 11/198 [00:03<00:43,  4.26it/s]\u001b[A\nTrain Epoch 1:   6%|‚ñå         | 12/198 [00:03<00:45,  4.09it/s]\u001b[A\nTrain Epoch 1:   7%|‚ñã         | 13/198 [00:03<00:49,  3.77it/s]\u001b[A\nTrain Epoch 1:   7%|‚ñã         | 14/198 [00:03<00:49,  3.74it/s]\u001b[A\nTrain Epoch 1:   8%|‚ñä         | 15/198 [00:04<00:48,  3.81it/s]\u001b[A\nTrain Epoch 1:   8%|‚ñä         | 16/198 [00:04<00:47,  3.86it/s]\u001b[A\nTrain Epoch 1:   9%|‚ñä         | 17/198 [00:04<00:46,  3.93it/s]\u001b[A\nTrain Epoch 1:   9%|‚ñâ         | 18/198 [00:04<00:45,  3.95it/s]\u001b[A\nTrain Epoch 1:  10%|‚ñâ         | 19/198 [00:05<00:45,  3.96it/s]\u001b[A\nTrain Epoch 1:  10%|‚ñà         | 20/198 [00:05<00:44,  4.00it/s]\u001b[A\nTrain Epoch 1:  11%|‚ñà         | 21/198 [00:05<00:44,  3.95it/s]\u001b[A\nTrain Epoch 1:  11%|‚ñà         | 22/198 [00:05<00:44,  3.98it/s]\u001b[A\nTrain Epoch 1:  12%|‚ñà‚ñè        | 23/198 [00:06<00:43,  4.03it/s]\u001b[A\nTrain Epoch 1:  12%|‚ñà‚ñè        | 24/198 [00:06<00:42,  4.07it/s]\u001b[A\nTrain Epoch 1:  13%|‚ñà‚ñé        | 25/198 [00:06<00:42,  4.09it/s]\u001b[A\nTrain Epoch 1:  13%|‚ñà‚ñé        | 26/198 [00:06<00:42,  4.03it/s]\u001b[A\nTrain Epoch 1:  14%|‚ñà‚ñé        | 27/198 [00:07<00:41,  4.08it/s]\u001b[A\nTrain Epoch 1:  14%|‚ñà‚ñç        | 28/198 [00:07<00:41,  4.12it/s]\u001b[A\nTrain Epoch 1:  15%|‚ñà‚ñç        | 29/198 [00:07<00:41,  4.10it/s]\u001b[A\nTrain Epoch 1:  15%|‚ñà‚ñå        | 30/198 [00:07<00:41,  4.07it/s]\u001b[A\nTrain Epoch 1:  16%|‚ñà‚ñå        | 31/198 [00:08<00:40,  4.11it/s]\u001b[A\nTrain Epoch 1:  16%|‚ñà‚ñå        | 32/198 [00:08<00:40,  4.11it/s]\u001b[A\nTrain Epoch 1:  17%|‚ñà‚ñã        | 33/198 [00:08<00:40,  4.12it/s]\u001b[A\nTrain Epoch 1:  17%|‚ñà‚ñã        | 34/198 [00:08<00:40,  4.04it/s]\u001b[A\nTrain Epoch 1:  18%|‚ñà‚ñä        | 35/198 [00:09<00:40,  4.05it/s]\u001b[A\nTrain Epoch 1:  18%|‚ñà‚ñä        | 36/198 [00:09<00:39,  4.06it/s]\u001b[A\nTrain Epoch 1:  19%|‚ñà‚ñä        | 37/198 [00:09<00:41,  3.92it/s]\u001b[A\nTrain Epoch 1:  19%|‚ñà‚ñâ        | 38/198 [00:09<00:39,  4.01it/s]\u001b[A\nTrain Epoch 1:  20%|‚ñà‚ñâ        | 39/198 [00:10<00:39,  4.06it/s]\u001b[A\nTrain Epoch 1:  20%|‚ñà‚ñà        | 40/198 [00:10<00:38,  4.06it/s]\u001b[A\nTrain Epoch 1:  21%|‚ñà‚ñà        | 41/198 [00:10<00:39,  4.00it/s]\u001b[A\nTrain Epoch 1:  21%|‚ñà‚ñà        | 42/198 [00:10<00:38,  4.02it/s]\u001b[A\nTrain Epoch 1:  22%|‚ñà‚ñà‚ñè       | 43/198 [00:11<00:39,  3.93it/s]\u001b[A\nTrain Epoch 1:  22%|‚ñà‚ñà‚ñè       | 44/198 [00:11<00:38,  3.96it/s]\u001b[A\nTrain Epoch 1:  23%|‚ñà‚ñà‚ñé       | 45/198 [00:11<00:38,  3.94it/s]\u001b[A\nTrain Epoch 1:  23%|‚ñà‚ñà‚ñé       | 46/198 [00:11<00:38,  3.99it/s]\u001b[A\nTrain Epoch 1:  24%|‚ñà‚ñà‚ñé       | 47/198 [00:12<00:37,  4.02it/s]\u001b[A\nTrain Epoch 1:  24%|‚ñà‚ñà‚ñç       | 48/198 [00:12<00:36,  4.06it/s]\u001b[A\nTrain Epoch 1:  25%|‚ñà‚ñà‚ñç       | 49/198 [00:12<00:36,  4.08it/s]\u001b[A\nTrain Epoch 1:  25%|‚ñà‚ñà‚ñå       | 50/198 [00:12<00:35,  4.15it/s]\u001b[A\nTrain Epoch 1:  26%|‚ñà‚ñà‚ñå       | 51/198 [00:13<00:35,  4.16it/s]\u001b[A\nTrain Epoch 1:  26%|‚ñà‚ñà‚ñã       | 52/198 [00:13<00:35,  4.16it/s]\u001b[A\nTrain Epoch 1:  27%|‚ñà‚ñà‚ñã       | 53/198 [00:13<00:34,  4.18it/s]\u001b[A\nTrain Epoch 1:  27%|‚ñà‚ñà‚ñã       | 54/198 [00:13<00:34,  4.18it/s]\u001b[A\nTrain Epoch 1:  28%|‚ñà‚ñà‚ñä       | 55/198 [00:13<00:34,  4.18it/s]\u001b[A\nTrain Epoch 1:  28%|‚ñà‚ñà‚ñä       | 56/198 [00:14<00:34,  4.17it/s]\u001b[A\nTrain Epoch 1:  29%|‚ñà‚ñà‚ñâ       | 57/198 [00:14<00:33,  4.21it/s]\u001b[A\nTrain Epoch 1:  29%|‚ñà‚ñà‚ñâ       | 58/198 [00:14<00:35,  3.89it/s]\u001b[A\nTrain Epoch 1:  30%|‚ñà‚ñà‚ñâ       | 59/198 [00:14<00:35,  3.97it/s]\u001b[A\nTrain Epoch 1:  30%|‚ñà‚ñà‚ñà       | 60/198 [00:15<00:34,  4.02it/s]\u001b[A\nTrain Epoch 1:  31%|‚ñà‚ñà‚ñà       | 61/198 [00:15<00:34,  4.02it/s]\u001b[A\nTrain Epoch 1:  31%|‚ñà‚ñà‚ñà‚ñè      | 62/198 [00:15<00:34,  3.98it/s]\u001b[A\nTrain Epoch 1:  32%|‚ñà‚ñà‚ñà‚ñè      | 63/198 [00:15<00:33,  4.05it/s]\u001b[A\nTrain Epoch 1:  32%|‚ñà‚ñà‚ñà‚ñè      | 64/198 [00:16<00:32,  4.09it/s]\u001b[A\nTrain Epoch 1:  33%|‚ñà‚ñà‚ñà‚ñé      | 65/198 [00:16<00:32,  4.11it/s]\u001b[A\nTrain Epoch 1:  33%|‚ñà‚ñà‚ñà‚ñé      | 66/198 [00:16<00:32,  4.12it/s]\u001b[A\nTrain Epoch 1:  34%|‚ñà‚ñà‚ñà‚ñç      | 67/198 [00:16<00:31,  4.11it/s]\u001b[A\nTrain Epoch 1:  34%|‚ñà‚ñà‚ñà‚ñç      | 68/198 [00:17<00:31,  4.15it/s]\u001b[A\nTrain Epoch 1:  35%|‚ñà‚ñà‚ñà‚ñç      | 69/198 [00:17<00:31,  4.06it/s]\u001b[A\nTrain Epoch 1:  35%|‚ñà‚ñà‚ñà‚ñå      | 70/198 [00:17<00:31,  4.07it/s]\u001b[A\nTrain Epoch 1:  36%|‚ñà‚ñà‚ñà‚ñå      | 71/198 [00:17<00:31,  4.09it/s]\u001b[A\nTrain Epoch 1:  36%|‚ñà‚ñà‚ñà‚ñã      | 72/198 [00:18<00:31,  4.06it/s]\u001b[A\nTrain Epoch 1:  37%|‚ñà‚ñà‚ñà‚ñã      | 73/198 [00:18<00:31,  4.02it/s]\u001b[A\nTrain Epoch 1:  37%|‚ñà‚ñà‚ñà‚ñã      | 74/198 [00:18<00:30,  4.05it/s]\u001b[A\nTrain Epoch 1:  38%|‚ñà‚ñà‚ñà‚ñä      | 75/198 [00:18<00:30,  4.03it/s]\u001b[A\nTrain Epoch 1:  38%|‚ñà‚ñà‚ñà‚ñä      | 76/198 [00:19<00:30,  4.06it/s]\u001b[A\nTrain Epoch 1:  39%|‚ñà‚ñà‚ñà‚ñâ      | 77/198 [00:19<00:29,  4.09it/s]\u001b[A\nTrain Epoch 1:  39%|‚ñà‚ñà‚ñà‚ñâ      | 78/198 [00:19<00:29,  4.08it/s]\u001b[A\nTrain Epoch 1:  40%|‚ñà‚ñà‚ñà‚ñâ      | 79/198 [00:19<00:29,  4.01it/s]\u001b[A\nTrain Epoch 1:  40%|‚ñà‚ñà‚ñà‚ñà      | 80/198 [00:20<00:29,  4.01it/s]\u001b[A\nTrain Epoch 1:  41%|‚ñà‚ñà‚ñà‚ñà      | 81/198 [00:20<00:28,  4.04it/s]\u001b[A\nTrain Epoch 1:  41%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 82/198 [00:20<00:28,  4.06it/s]\u001b[A\nTrain Epoch 1:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 83/198 [00:20<00:28,  4.10it/s]\u001b[A\nTrain Epoch 1:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 84/198 [00:21<00:27,  4.12it/s]\u001b[A\nTrain Epoch 1:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 85/198 [00:21<00:27,  4.13it/s]\u001b[A\nTrain Epoch 1:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 86/198 [00:21<00:27,  4.13it/s]\u001b[A\nTrain Epoch 1:  44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 87/198 [00:21<00:26,  4.14it/s]\u001b[A\nTrain Epoch 1:  44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 88/198 [00:22<00:26,  4.15it/s]\u001b[A\nTrain Epoch 1:  45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 89/198 [00:22<00:26,  4.10it/s]\u001b[A\nTrain Epoch 1:  45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 90/198 [00:22<00:26,  4.12it/s]\u001b[A\nTrain Epoch 1:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 91/198 [00:22<00:26,  4.10it/s]\u001b[A\nTrain Epoch 1:  46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 92/198 [00:23<00:26,  4.05it/s]\u001b[A\nTrain Epoch 1:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 93/198 [00:23<00:25,  4.07it/s]\u001b[A\nTrain Epoch 1:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 94/198 [00:23<00:25,  4.00it/s]\u001b[A\nTrain Epoch 1:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 95/198 [00:23<00:25,  4.05it/s]\u001b[A\nTrain Epoch 1:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 96/198 [00:24<00:25,  4.06it/s]\u001b[A\nTrain Epoch 1:  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 97/198 [00:24<00:24,  4.06it/s]\u001b[A\nTrain Epoch 1:  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 98/198 [00:24<00:24,  4.03it/s]\u001b[A\nTrain Epoch 1:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 99/198 [00:24<00:24,  4.06it/s]\u001b[A\nTrain Epoch 1:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 100/198 [00:25<00:24,  3.98it/s]\u001b[A\nTrain Epoch 1:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 101/198 [00:25<00:24,  4.02it/s]\u001b[A\nTrain Epoch 1:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 102/198 [00:25<00:23,  4.02it/s]\u001b[A\nTrain Epoch 1:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 103/198 [00:25<00:23,  4.03it/s]\u001b[A\nTrain Epoch 1:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 104/198 [00:26<00:23,  4.05it/s]\u001b[A\nTrain Epoch 1:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 105/198 [00:26<00:22,  4.09it/s]\u001b[A\nTrain Epoch 1:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 106/198 [00:26<00:22,  4.11it/s]\u001b[A\nTrain Epoch 1:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 107/198 [00:26<00:22,  4.13it/s]\u001b[A\nTrain Epoch 1:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 108/198 [00:26<00:21,  4.14it/s]\u001b[A\nTrain Epoch 1:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 109/198 [00:27<00:21,  4.13it/s]\u001b[A\nTrain Epoch 1:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 110/198 [00:27<00:21,  4.14it/s]\u001b[A\nTrain Epoch 1:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 111/198 [00:27<00:21,  4.13it/s]\u001b[A\nTrain Epoch 1:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 112/198 [00:27<00:20,  4.13it/s]\u001b[A\nTrain Epoch 1:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 113/198 [00:28<00:20,  4.13it/s]\u001b[A\nTrain Epoch 1:  58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 114/198 [00:28<00:20,  4.10it/s]\u001b[A\nTrain Epoch 1:  58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 115/198 [00:28<00:20,  4.10it/s]\u001b[A\nTrain Epoch 1:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 116/198 [00:28<00:20,  4.02it/s]\u001b[A\nTrain Epoch 1:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 117/198 [00:29<00:19,  4.08it/s]\u001b[A\nTrain Epoch 1:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 118/198 [00:29<00:19,  4.08it/s]\u001b[A\nTrain Epoch 1:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 119/198 [00:29<00:19,  4.10it/s]\u001b[A\nTrain Epoch 1:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 120/198 [00:29<00:19,  4.10it/s]\u001b[A\nTrain Epoch 1:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 121/198 [00:30<00:19,  4.03it/s]\u001b[A\nTrain Epoch 1:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 122/198 [00:30<00:19,  3.92it/s]\u001b[A\nTrain Epoch 1:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 123/198 [00:30<00:18,  3.99it/s]\u001b[A\nTrain Epoch 1:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 124/198 [00:30<00:18,  3.99it/s]\u001b[A\nTrain Epoch 1:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 125/198 [00:31<00:18,  4.03it/s]\u001b[A\nTrain Epoch 1:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 126/198 [00:31<00:17,  4.08it/s]\u001b[A\nTrain Epoch 1:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 127/198 [00:31<00:17,  3.97it/s]\u001b[A\nTrain Epoch 1:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 128/198 [00:31<00:17,  4.03it/s]\u001b[A\nTrain Epoch 1:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 129/198 [00:32<00:17,  4.03it/s]\u001b[A\nTrain Epoch 1:  66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 130/198 [00:32<00:16,  4.06it/s]\u001b[A\nTrain Epoch 1:  66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 131/198 [00:32<00:16,  4.08it/s]\u001b[A\nTrain Epoch 1:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 132/198 [00:32<00:16,  4.10it/s]\u001b[A\nTrain Epoch 1:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 133/198 [00:33<00:15,  4.12it/s]\u001b[A\nTrain Epoch 1:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 134/198 [00:33<00:15,  4.14it/s]\u001b[A\nTrain Epoch 1:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 135/198 [00:33<00:15,  4.14it/s]\u001b[A\nTrain Epoch 1:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 136/198 [00:33<00:15,  4.04it/s]\u001b[A\nTrain Epoch 1:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 137/198 [00:34<00:14,  4.09it/s]\u001b[A\nTrain Epoch 1:  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 138/198 [00:34<00:14,  4.12it/s]\u001b[A\nTrain Epoch 1:  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 139/198 [00:34<00:14,  4.12it/s]\u001b[A\nTrain Epoch 1:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 140/198 [00:34<00:14,  4.10it/s]\u001b[A\nTrain Epoch 1:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 141/198 [00:35<00:13,  4.12it/s]\u001b[A\nTrain Epoch 1:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 142/198 [00:35<00:13,  4.14it/s]\u001b[A\nTrain Epoch 1:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 143/198 [00:35<00:13,  4.10it/s]\u001b[A\nTrain Epoch 1:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 144/198 [00:35<00:13,  4.01it/s]\u001b[A\nTrain Epoch 1:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 145/198 [00:36<00:13,  4.04it/s]\u001b[A\nTrain Epoch 1:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 146/198 [00:36<00:12,  4.07it/s]\u001b[A\nTrain Epoch 1:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 147/198 [00:36<00:12,  4.08it/s]\u001b[A\nTrain Epoch 1:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 148/198 [00:36<00:12,  4.11it/s]\u001b[A\nTrain Epoch 1:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 149/198 [00:37<00:11,  4.14it/s]\u001b[A\nTrain Epoch 1:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 150/198 [00:37<00:11,  4.15it/s]\u001b[A\nTrain Epoch 1:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 151/198 [00:37<00:11,  4.16it/s]\u001b[A\nTrain Epoch 1:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 152/198 [00:37<00:11,  4.16it/s]\u001b[A\nTrain Epoch 1:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 153/198 [00:38<00:11,  4.04it/s]\u001b[A\nTrain Epoch 1:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 154/198 [00:38<00:11,  4.00it/s]\u001b[A\nTrain Epoch 1:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 155/198 [00:38<00:10,  4.04it/s]\u001b[A\nTrain Epoch 1:  79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 156/198 [00:38<00:10,  4.06it/s]\u001b[A\nTrain Epoch 1:  79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 157/198 [00:39<00:10,  4.09it/s]\u001b[A\nTrain Epoch 1:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 158/198 [00:39<00:09,  4.11it/s]\u001b[A\nTrain Epoch 1:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 159/198 [00:39<00:09,  4.06it/s]\u001b[A\nTrain Epoch 1:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 160/198 [00:39<00:09,  4.10it/s]\u001b[A\nTrain Epoch 1:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 161/198 [00:39<00:08,  4.12it/s]\u001b[A\nTrain Epoch 1:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 162/198 [00:40<00:08,  4.13it/s]\u001b[A\nTrain Epoch 1:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 163/198 [00:40<00:08,  4.13it/s]\u001b[A\nTrain Epoch 1:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 164/198 [00:40<00:08,  4.13it/s]\u001b[A\nTrain Epoch 1:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 165/198 [00:40<00:08,  4.12it/s]\u001b[A\nTrain Epoch 1:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 166/198 [00:41<00:07,  4.13it/s]\u001b[A\nTrain Epoch 1:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 167/198 [00:41<00:07,  4.12it/s]\u001b[A\nTrain Epoch 1:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 168/198 [00:41<00:07,  4.13it/s]\u001b[A\nTrain Epoch 1:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 169/198 [00:41<00:07,  4.04it/s]\u001b[A\nTrain Epoch 1:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 170/198 [00:42<00:06,  4.06it/s]\u001b[A\nTrain Epoch 1:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 171/198 [00:42<00:06,  4.05it/s]\u001b[A\nTrain Epoch 1:  87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 172/198 [00:42<00:06,  4.07it/s]\u001b[A\nTrain Epoch 1:  87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 173/198 [00:42<00:06,  4.05it/s]\u001b[A\nTrain Epoch 1:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 174/198 [00:43<00:06,  3.92it/s]\u001b[A\nTrain Epoch 1:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 175/198 [00:43<00:05,  3.94it/s]\u001b[A\nTrain Epoch 1:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 176/198 [00:43<00:05,  4.02it/s]\u001b[A\nTrain Epoch 1:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 177/198 [00:43<00:05,  4.07it/s]\u001b[A\nTrain Epoch 1:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 178/198 [00:44<00:04,  4.10it/s]\u001b[A\nTrain Epoch 1:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 179/198 [00:44<00:04,  4.12it/s]\u001b[A\nTrain Epoch 1:  91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 180/198 [00:44<00:04,  4.17it/s]\u001b[A\nTrain Epoch 1:  91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 181/198 [00:44<00:04,  4.17it/s]\u001b[A\nTrain Epoch 1:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 182/198 [00:45<00:03,  4.17it/s]\u001b[A\nTrain Epoch 1:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 183/198 [00:45<00:03,  4.19it/s]\u001b[A\nTrain Epoch 1:  93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 184/198 [00:45<00:03,  4.18it/s]\u001b[A\nTrain Epoch 1:  93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 185/198 [00:45<00:03,  4.17it/s]\u001b[A\nTrain Epoch 1:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 186/198 [00:46<00:02,  4.15it/s]\u001b[A\nTrain Epoch 1:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 187/198 [00:46<00:02,  4.13it/s]\u001b[A\nTrain Epoch 1:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 188/198 [00:46<00:02,  4.14it/s]\u001b[A\nTrain Epoch 1:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 189/198 [00:46<00:02,  4.03it/s]\u001b[A\nTrain Epoch 1:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 190/198 [00:47<00:01,  4.09it/s]\u001b[A\nTrain Epoch 1:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 191/198 [00:47<00:01,  4.12it/s]\u001b[A\nTrain Epoch 1:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 192/198 [00:47<00:01,  4.14it/s]\u001b[A\nTrain Epoch 1:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 193/198 [00:47<00:01,  4.14it/s]\u001b[A\nTrain Epoch 1:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 194/198 [00:48<00:00,  4.12it/s]\u001b[A\nTrain Epoch 1:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 195/198 [00:48<00:00,  4.18it/s]\u001b[A\nTrain Epoch 1:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 196/198 [00:48<00:00,  4.18it/s]\u001b[A\nTrain Epoch 1:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 197/198 [00:48<00:00,  4.16it/s]\u001b[A\nTrain Epoch 1: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 198/198 [00:48<00:00,  4.05it/s]\u001b[A\n\nValidation Epoch 1:   0%|          | 0/29 [00:00<?, ?it/s]\u001b[A\nValidation Epoch 1:   7%|‚ñã         | 2/29 [00:00<00:01, 13.81it/s]\u001b[A\nValidation Epoch 1:  14%|‚ñà‚ñç        | 4/29 [00:00<00:01, 13.68it/s]\u001b[A\nValidation Epoch 1:  21%|‚ñà‚ñà        | 6/29 [00:00<00:01, 13.19it/s]\u001b[A\nValidation Epoch 1:  28%|‚ñà‚ñà‚ñä       | 8/29 [00:00<00:01, 13.50it/s]\u001b[A\nValidation Epoch 1:  34%|‚ñà‚ñà‚ñà‚ñç      | 10/29 [00:00<00:01, 13.68it/s]\u001b[A\nValidation Epoch 1:  41%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 12/29 [00:00<00:01, 13.81it/s]\u001b[A\nValidation Epoch 1:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 14/29 [00:01<00:01, 13.52it/s]\u001b[A\nValidation Epoch 1:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 16/29 [00:01<00:00, 13.69it/s]\u001b[A\nValidation Epoch 1:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 18/29 [00:01<00:00, 14.16it/s]\u001b[A\nValidation Epoch 1:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 20/29 [00:01<00:00, 13.74it/s]\u001b[A\nValidation Epoch 1:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 22/29 [00:01<00:00, 13.75it/s]\u001b[A\nValidation Epoch 1:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 24/29 [00:01<00:00, 13.90it/s]\u001b[A\nValidation Epoch 1:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 26/29 [00:01<00:00, 13.95it/s]\u001b[A\nValidation Epoch 1: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 29/29 [00:02<00:00, 14.11it/s]\u001b[A\n","output_type":"stream"},{"name":"stdout","text":"Epoch [1/20]\nTrain Loss: 1.0833 | Train Acc: 0.4091\nVal Loss: 1.0657 | Val Acc: 0.4789\n‚úÖ Validation loss improved ‚Äî model saved.\n--------------------------------------------------\n","output_type":"stream"},{"name":"stderr","text":"\nTrain Epoch 2:   0%|          | 0/198 [00:00<?, ?it/s]\u001b[A\nTrain Epoch 2:   1%|          | 1/198 [00:00<00:48,  4.04it/s]\u001b[A\nTrain Epoch 2:   1%|          | 2/198 [00:00<00:48,  4.07it/s]\u001b[A\nTrain Epoch 2:   2%|‚ñè         | 3/198 [00:00<00:49,  3.94it/s]\u001b[A\nTrain Epoch 2:   2%|‚ñè         | 4/198 [00:00<00:48,  4.02it/s]\u001b[A\nTrain Epoch 2:   3%|‚ñé         | 5/198 [00:01<00:47,  4.07it/s]\u001b[A\nTrain Epoch 2:   3%|‚ñé         | 6/198 [00:01<00:46,  4.11it/s]\u001b[A\nTrain Epoch 2:   4%|‚ñé         | 7/198 [00:01<00:46,  4.12it/s]\u001b[A\nTrain Epoch 2:   4%|‚ñç         | 8/198 [00:01<00:46,  4.12it/s]\u001b[A\nTrain Epoch 2:   5%|‚ñç         | 9/198 [00:02<00:45,  4.19it/s]\u001b[A\nTrain Epoch 2:   5%|‚ñå         | 10/198 [00:02<00:44,  4.18it/s]\u001b[A\nTrain Epoch 2:   6%|‚ñå         | 11/198 [00:02<00:45,  4.07it/s]\u001b[A\nTrain Epoch 2:   6%|‚ñå         | 12/198 [00:02<00:45,  4.11it/s]\u001b[A\nTrain Epoch 2:   7%|‚ñã         | 13/198 [00:03<00:44,  4.14it/s]\u001b[A\nTrain Epoch 2:   7%|‚ñã         | 14/198 [00:03<00:44,  4.16it/s]\u001b[A\nTrain Epoch 2:   8%|‚ñä         | 15/198 [00:03<00:43,  4.17it/s]\u001b[A\nTrain Epoch 2:   8%|‚ñä         | 16/198 [00:03<00:44,  4.11it/s]\u001b[A\nTrain Epoch 2:   9%|‚ñä         | 17/198 [00:04<00:44,  4.02it/s]\u001b[A\nTrain Epoch 2:   9%|‚ñâ         | 18/198 [00:04<00:44,  4.07it/s]\u001b[A\nTrain Epoch 2:  10%|‚ñâ         | 19/198 [00:04<00:43,  4.11it/s]\u001b[A\nTrain Epoch 2:  10%|‚ñà         | 20/198 [00:04<00:43,  4.13it/s]\u001b[A\nTrain Epoch 2:  11%|‚ñà         | 21/198 [00:05<00:42,  4.14it/s]\u001b[A\nTrain Epoch 2:  11%|‚ñà         | 22/198 [00:05<00:43,  4.02it/s]\u001b[A\nTrain Epoch 2:  12%|‚ñà‚ñè        | 23/198 [00:05<00:43,  4.06it/s]\u001b[A\nTrain Epoch 2:  12%|‚ñà‚ñè        | 24/198 [00:05<00:42,  4.08it/s]\u001b[A\nTrain Epoch 2:  13%|‚ñà‚ñé        | 25/198 [00:06<00:42,  4.12it/s]\u001b[A\nTrain Epoch 2:  13%|‚ñà‚ñé        | 26/198 [00:06<00:41,  4.13it/s]\u001b[A\nTrain Epoch 2:  14%|‚ñà‚ñé        | 27/198 [00:06<00:42,  4.03it/s]\u001b[A\nTrain Epoch 2:  14%|‚ñà‚ñç        | 28/198 [00:06<00:41,  4.08it/s]\u001b[A\nTrain Epoch 2:  15%|‚ñà‚ñç        | 29/198 [00:07<00:40,  4.14it/s]\u001b[A\nTrain Epoch 2:  15%|‚ñà‚ñå        | 30/198 [00:07<00:40,  4.16it/s]\u001b[A\nTrain Epoch 2:  16%|‚ñà‚ñå        | 31/198 [00:07<00:40,  4.17it/s]\u001b[A\nTrain Epoch 2:  16%|‚ñà‚ñå        | 32/198 [00:07<00:42,  3.94it/s]\u001b[A\nTrain Epoch 2:  17%|‚ñà‚ñã        | 33/198 [00:08<00:42,  3.93it/s]\u001b[A\nTrain Epoch 2:  17%|‚ñà‚ñã        | 34/198 [00:08<00:44,  3.69it/s]\u001b[A\nTrain Epoch 2:  18%|‚ñà‚ñä        | 35/198 [00:08<00:51,  3.17it/s]\u001b[A\nTrain Epoch 2:  18%|‚ñà‚ñä        | 36/198 [00:09<00:48,  3.33it/s]\u001b[A\nTrain Epoch 2:  19%|‚ñà‚ñä        | 37/198 [00:09<00:45,  3.53it/s]\u001b[A\nTrain Epoch 2:  19%|‚ñà‚ñâ        | 38/198 [00:09<00:43,  3.66it/s]\u001b[A\nTrain Epoch 2:  20%|‚ñà‚ñâ        | 39/198 [00:09<00:41,  3.80it/s]\u001b[A\nTrain Epoch 2:  20%|‚ñà‚ñà        | 40/198 [00:10<00:40,  3.91it/s]\u001b[A\nTrain Epoch 2:  21%|‚ñà‚ñà        | 41/198 [00:10<00:39,  4.00it/s]\u001b[A\nTrain Epoch 2:  21%|‚ñà‚ñà        | 42/198 [00:10<00:38,  4.04it/s]\u001b[A\nTrain Epoch 2:  22%|‚ñà‚ñà‚ñè       | 43/198 [00:10<00:38,  4.08it/s]\u001b[A\nTrain Epoch 2:  22%|‚ñà‚ñà‚ñè       | 44/198 [00:11<00:38,  4.04it/s]\u001b[A\nTrain Epoch 2:  23%|‚ñà‚ñà‚ñé       | 45/198 [00:11<00:37,  4.04it/s]\u001b[A\nTrain Epoch 2:  23%|‚ñà‚ñà‚ñé       | 46/198 [00:11<00:37,  4.04it/s]\u001b[A\nTrain Epoch 2:  24%|‚ñà‚ñà‚ñé       | 47/198 [00:11<00:37,  4.08it/s]\u001b[A\nTrain Epoch 2:  24%|‚ñà‚ñà‚ñç       | 48/198 [00:12<00:37,  4.02it/s]\u001b[A\nTrain Epoch 2:  25%|‚ñà‚ñà‚ñç       | 49/198 [00:12<00:36,  4.04it/s]\u001b[A\nTrain Epoch 2:  25%|‚ñà‚ñà‚ñå       | 50/198 [00:12<00:37,  3.96it/s]\u001b[A\nTrain Epoch 2:  26%|‚ñà‚ñà‚ñå       | 51/198 [00:12<00:36,  4.00it/s]\u001b[A\nTrain Epoch 2:  26%|‚ñà‚ñà‚ñã       | 52/198 [00:13<00:36,  4.04it/s]\u001b[A\nTrain Epoch 2:  27%|‚ñà‚ñà‚ñã       | 53/198 [00:13<00:35,  4.06it/s]\u001b[A\nTrain Epoch 2:  27%|‚ñà‚ñà‚ñã       | 54/198 [00:13<00:35,  4.08it/s]\u001b[A\nTrain Epoch 2:  28%|‚ñà‚ñà‚ñä       | 55/198 [00:13<00:35,  4.05it/s]\u001b[A\nTrain Epoch 2:  28%|‚ñà‚ñà‚ñä       | 56/198 [00:13<00:35,  4.05it/s]\u001b[A\nTrain Epoch 2:  29%|‚ñà‚ñà‚ñâ       | 57/198 [00:14<00:34,  4.08it/s]\u001b[A\nTrain Epoch 2:  29%|‚ñà‚ñà‚ñâ       | 58/198 [00:14<00:34,  4.03it/s]\u001b[A\nTrain Epoch 2:  30%|‚ñà‚ñà‚ñâ       | 59/198 [00:14<00:34,  4.05it/s]\u001b[A\nTrain Epoch 2:  30%|‚ñà‚ñà‚ñà       | 60/198 [00:14<00:34,  4.06it/s]\u001b[A\nTrain Epoch 2:  31%|‚ñà‚ñà‚ñà       | 61/198 [00:15<00:33,  4.07it/s]\u001b[A\nTrain Epoch 2:  31%|‚ñà‚ñà‚ñà‚ñè      | 62/198 [00:15<00:33,  4.08it/s]\u001b[A\nTrain Epoch 2:  32%|‚ñà‚ñà‚ñà‚ñè      | 63/198 [00:15<00:32,  4.10it/s]\u001b[A\nTrain Epoch 2:  32%|‚ñà‚ñà‚ñà‚ñè      | 64/198 [00:15<00:32,  4.09it/s]\u001b[A\nTrain Epoch 2:  33%|‚ñà‚ñà‚ñà‚ñé      | 65/198 [00:16<00:32,  4.10it/s]\u001b[A\nTrain Epoch 2:  33%|‚ñà‚ñà‚ñà‚ñé      | 66/198 [00:16<00:32,  4.10it/s]\u001b[A\nTrain Epoch 2:  34%|‚ñà‚ñà‚ñà‚ñç      | 67/198 [00:16<00:31,  4.13it/s]\u001b[A\nTrain Epoch 2:  34%|‚ñà‚ñà‚ñà‚ñç      | 68/198 [00:16<00:31,  4.14it/s]\u001b[A\nTrain Epoch 2:  35%|‚ñà‚ñà‚ñà‚ñç      | 69/198 [00:17<00:31,  4.13it/s]\u001b[A\nTrain Epoch 2:  35%|‚ñà‚ñà‚ñà‚ñå      | 70/198 [00:17<00:31,  4.12it/s]\u001b[A\nTrain Epoch 2:  36%|‚ñà‚ñà‚ñà‚ñå      | 71/198 [00:17<00:31,  4.08it/s]\u001b[A\nTrain Epoch 2:  36%|‚ñà‚ñà‚ñà‚ñã      | 72/198 [00:17<00:30,  4.10it/s]\u001b[A\nTrain Epoch 2:  37%|‚ñà‚ñà‚ñà‚ñã      | 73/198 [00:18<00:30,  4.11it/s]\u001b[A\nTrain Epoch 2:  37%|‚ñà‚ñà‚ñà‚ñã      | 74/198 [00:18<00:30,  4.02it/s]\u001b[A\nTrain Epoch 2:  38%|‚ñà‚ñà‚ñà‚ñä      | 75/198 [00:18<00:30,  4.05it/s]\u001b[A\nTrain Epoch 2:  38%|‚ñà‚ñà‚ñà‚ñä      | 76/198 [00:18<00:30,  3.95it/s]\u001b[A\nTrain Epoch 2:  39%|‚ñà‚ñà‚ñà‚ñâ      | 77/198 [00:19<00:31,  3.86it/s]\u001b[A\nTrain Epoch 2:  39%|‚ñà‚ñà‚ñà‚ñâ      | 78/198 [00:19<00:30,  3.93it/s]\u001b[A\nTrain Epoch 2:  40%|‚ñà‚ñà‚ñà‚ñâ      | 79/198 [00:19<00:30,  3.91it/s]\u001b[A\nTrain Epoch 2:  40%|‚ñà‚ñà‚ñà‚ñà      | 80/198 [00:19<00:30,  3.89it/s]\u001b[A\nTrain Epoch 2:  41%|‚ñà‚ñà‚ñà‚ñà      | 81/198 [00:20<00:29,  3.90it/s]\u001b[A\nTrain Epoch 2:  41%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 82/198 [00:20<00:29,  3.96it/s]\u001b[A\nTrain Epoch 2:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 83/198 [00:20<00:28,  4.03it/s]\u001b[A\nTrain Epoch 2:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 84/198 [00:20<00:28,  3.97it/s]\u001b[A\nTrain Epoch 2:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 85/198 [00:21<00:29,  3.83it/s]\u001b[A\nTrain Epoch 2:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 86/198 [00:21<00:28,  3.95it/s]\u001b[A\nTrain Epoch 2:  44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 87/198 [00:21<00:28,  3.93it/s]\u001b[A\nTrain Epoch 2:  44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 88/198 [00:21<00:28,  3.91it/s]\u001b[A\nTrain Epoch 2:  45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 89/198 [00:22<00:27,  3.90it/s]\u001b[A\nTrain Epoch 2:  45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 90/198 [00:22<00:27,  3.97it/s]\u001b[A\nTrain Epoch 2:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 91/198 [00:22<00:27,  3.94it/s]\u001b[A\nTrain Epoch 2:  46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 92/198 [00:22<00:26,  3.95it/s]\u001b[A\nTrain Epoch 2:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 93/198 [00:23<00:26,  3.91it/s]\u001b[A\nTrain Epoch 2:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 94/198 [00:23<00:26,  3.92it/s]\u001b[A\nTrain Epoch 2:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 95/198 [00:23<00:25,  3.97it/s]\u001b[A\nTrain Epoch 2:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 96/198 [00:23<00:25,  4.02it/s]\u001b[A\nTrain Epoch 2:  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 97/198 [00:24<00:25,  4.03it/s]\u001b[A\nTrain Epoch 2:  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 98/198 [00:24<00:24,  4.03it/s]\u001b[A\nTrain Epoch 2:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 99/198 [00:24<00:24,  4.08it/s]\u001b[A\nTrain Epoch 2:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 100/198 [00:24<00:24,  4.04it/s]\u001b[A\nTrain Epoch 2:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 101/198 [00:25<00:23,  4.09it/s]\u001b[A\nTrain Epoch 2:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 102/198 [00:25<00:23,  4.12it/s]\u001b[A\nTrain Epoch 2:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 103/198 [00:25<00:23,  4.05it/s]\u001b[A\nTrain Epoch 2:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 104/198 [00:25<00:23,  4.08it/s]\u001b[A\nTrain Epoch 2:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 105/198 [00:26<00:22,  4.10it/s]\u001b[A\nTrain Epoch 2:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 106/198 [00:26<00:22,  4.04it/s]\u001b[A\nTrain Epoch 2:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 107/198 [00:26<00:22,  4.06it/s]\u001b[A\nTrain Epoch 2:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 108/198 [00:26<00:22,  4.01it/s]\u001b[A\nTrain Epoch 2:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 109/198 [00:27<00:21,  4.06it/s]\u001b[A\nTrain Epoch 2:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 110/198 [00:27<00:22,  4.00it/s]\u001b[A\nTrain Epoch 2:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 111/198 [00:27<00:21,  4.02it/s]\u001b[A\nTrain Epoch 2:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 112/198 [00:27<00:21,  3.96it/s]\u001b[A\nTrain Epoch 2:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 113/198 [00:28<00:21,  3.92it/s]\u001b[A\nTrain Epoch 2:  58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 114/198 [00:28<00:21,  3.99it/s]\u001b[A\nTrain Epoch 2:  58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 115/198 [00:28<00:20,  3.97it/s]\u001b[A\nTrain Epoch 2:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 116/198 [00:28<00:20,  4.03it/s]\u001b[A\nTrain Epoch 2:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 117/198 [00:29<00:19,  4.07it/s]\u001b[A\nTrain Epoch 2:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 118/198 [00:29<00:19,  4.10it/s]\u001b[A\nTrain Epoch 2:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 119/198 [00:29<00:18,  4.17it/s]\u001b[A\nTrain Epoch 2:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 120/198 [00:29<00:18,  4.23it/s]\u001b[A\nTrain Epoch 2:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 121/198 [00:30<00:18,  4.26it/s]\u001b[A\nTrain Epoch 2:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 122/198 [00:30<00:17,  4.29it/s]\u001b[A\nTrain Epoch 2:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 123/198 [00:30<00:17,  4.31it/s]\u001b[A\nTrain Epoch 2:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 124/198 [00:30<00:17,  4.33it/s]\u001b[A\nTrain Epoch 2:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 125/198 [00:31<00:16,  4.35it/s]\u001b[A\nTrain Epoch 2:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 126/198 [00:31<00:16,  4.36it/s]\u001b[A\nTrain Epoch 2:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 127/198 [00:31<00:16,  4.37it/s]\u001b[A\nTrain Epoch 2:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 128/198 [00:31<00:16,  4.37it/s]\u001b[A\nTrain Epoch 2:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 129/198 [00:31<00:15,  4.37it/s]\u001b[A\nTrain Epoch 2:  66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 130/198 [00:32<00:15,  4.36it/s]\u001b[A\nTrain Epoch 2:  66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 131/198 [00:32<00:15,  4.36it/s]\u001b[A\nTrain Epoch 2:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 132/198 [00:32<00:15,  4.36it/s]\u001b[A\nTrain Epoch 2:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 133/198 [00:32<00:14,  4.36it/s]\u001b[A\nTrain Epoch 2:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 134/198 [00:33<00:14,  4.36it/s]\u001b[A\nTrain Epoch 2:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 135/198 [00:33<00:14,  4.36it/s]\u001b[A\nTrain Epoch 2:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 136/198 [00:33<00:14,  4.37it/s]\u001b[A\nTrain Epoch 2:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 137/198 [00:33<00:13,  4.37it/s]\u001b[A\nTrain Epoch 2:  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 138/198 [00:34<00:13,  4.37it/s]\u001b[A\nTrain Epoch 2:  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 139/198 [00:34<00:13,  4.37it/s]\u001b[A\nTrain Epoch 2:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 140/198 [00:34<00:13,  4.37it/s]\u001b[A\nTrain Epoch 2:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 141/198 [00:34<00:13,  4.37it/s]\u001b[A\nTrain Epoch 2:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 142/198 [00:34<00:12,  4.37it/s]\u001b[A\nTrain Epoch 2:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 143/198 [00:35<00:12,  4.37it/s]\u001b[A\nTrain Epoch 2:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 144/198 [00:35<00:12,  4.37it/s]\u001b[A\nTrain Epoch 2:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 145/198 [00:35<00:12,  4.37it/s]\u001b[A\nTrain Epoch 2:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 146/198 [00:35<00:11,  4.37it/s]\u001b[A\nTrain Epoch 2:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 147/198 [00:36<00:11,  4.37it/s]\u001b[A\nTrain Epoch 2:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 148/198 [00:36<00:11,  4.37it/s]\u001b[A\nTrain Epoch 2:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 149/198 [00:36<00:11,  4.37it/s]\u001b[A\nTrain Epoch 2:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 150/198 [00:36<00:10,  4.37it/s]\u001b[A\nTrain Epoch 2:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 151/198 [00:36<00:10,  4.37it/s]\u001b[A\nTrain Epoch 2:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 152/198 [00:37<00:10,  4.37it/s]\u001b[A\nTrain Epoch 2:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 153/198 [00:37<00:10,  4.38it/s]\u001b[A\nTrain Epoch 2:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 154/198 [00:37<00:10,  4.38it/s]\u001b[A\nTrain Epoch 2:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 155/198 [00:37<00:09,  4.38it/s]\u001b[A\nTrain Epoch 2:  79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 156/198 [00:38<00:09,  4.38it/s]\u001b[A\nTrain Epoch 2:  79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 157/198 [00:38<00:09,  4.38it/s]\u001b[A\nTrain Epoch 2:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 158/198 [00:38<00:09,  4.38it/s]\u001b[A\nTrain Epoch 2:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 159/198 [00:38<00:08,  4.38it/s]\u001b[A\nTrain Epoch 2:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 160/198 [00:39<00:08,  4.38it/s]\u001b[A\nTrain Epoch 2:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 161/198 [00:39<00:08,  4.37it/s]\u001b[A\nTrain Epoch 2:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 162/198 [00:39<00:08,  4.37it/s]\u001b[A\nTrain Epoch 2:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 163/198 [00:39<00:08,  4.37it/s]\u001b[A\nTrain Epoch 2:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 164/198 [00:39<00:07,  4.37it/s]\u001b[A\nTrain Epoch 2:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 165/198 [00:40<00:07,  4.38it/s]\u001b[A\nTrain Epoch 2:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 166/198 [00:40<00:07,  4.38it/s]\u001b[A\nTrain Epoch 2:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 167/198 [00:40<00:07,  4.37it/s]\u001b[A\nTrain Epoch 2:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 168/198 [00:40<00:06,  4.37it/s]\u001b[A\nTrain Epoch 2:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 169/198 [00:41<00:06,  4.38it/s]\u001b[A\nTrain Epoch 2:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 170/198 [00:41<00:06,  4.38it/s]\u001b[A\nTrain Epoch 2:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 171/198 [00:41<00:06,  4.38it/s]\u001b[A\nTrain Epoch 2:  87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 172/198 [00:41<00:05,  4.38it/s]\u001b[A\nTrain Epoch 2:  87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 173/198 [00:42<00:05,  4.37it/s]\u001b[A\nTrain Epoch 2:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 174/198 [00:42<00:05,  4.37it/s]\u001b[A\nTrain Epoch 2:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 175/198 [00:42<00:05,  4.37it/s]\u001b[A\nTrain Epoch 2:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 176/198 [00:42<00:05,  4.37it/s]\u001b[A\nTrain Epoch 2:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 177/198 [00:42<00:04,  4.38it/s]\u001b[A\nTrain Epoch 2:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 178/198 [00:43<00:04,  4.38it/s]\u001b[A\nTrain Epoch 2:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 179/198 [00:43<00:04,  4.38it/s]\u001b[A\nTrain Epoch 2:  91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 180/198 [00:43<00:04,  4.38it/s]\u001b[A\nTrain Epoch 2:  91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 181/198 [00:43<00:03,  4.39it/s]\u001b[A\nTrain Epoch 2:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 182/198 [00:44<00:03,  4.38it/s]\u001b[A\nTrain Epoch 2:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 183/198 [00:44<00:03,  4.38it/s]\u001b[A\nTrain Epoch 2:  93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 184/198 [00:44<00:03,  4.38it/s]\u001b[A\nTrain Epoch 2:  93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 185/198 [00:44<00:02,  4.38it/s]\u001b[A\nTrain Epoch 2:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 186/198 [00:44<00:02,  4.38it/s]\u001b[A\nTrain Epoch 2:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 187/198 [00:45<00:02,  4.38it/s]\u001b[A\nTrain Epoch 2:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 188/198 [00:45<00:02,  4.38it/s]\u001b[A\nTrain Epoch 2:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 189/198 [00:45<00:02,  4.37it/s]\u001b[A\nTrain Epoch 2:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 190/198 [00:45<00:01,  4.37it/s]\u001b[A\nTrain Epoch 2:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 191/198 [00:46<00:01,  4.37it/s]\u001b[A\nTrain Epoch 2:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 192/198 [00:46<00:01,  4.37it/s]\u001b[A\nTrain Epoch 2:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 193/198 [00:46<00:01,  4.38it/s]\u001b[A\nTrain Epoch 2:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 194/198 [00:46<00:00,  4.38it/s]\u001b[A\nTrain Epoch 2:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 195/198 [00:47<00:00,  4.38it/s]\u001b[A\nTrain Epoch 2:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 196/198 [00:47<00:00,  4.38it/s]\u001b[A\nTrain Epoch 2:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 197/198 [00:47<00:00,  4.38it/s]\u001b[A\nTrain Epoch 2: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 198/198 [00:47<00:00,  4.16it/s]\u001b[A\nValidation Epoch 2: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 29/29 [00:01<00:00, 17.29it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch [2/20]\nTrain Loss: 1.0671 | Train Acc: 0.4807\nVal Loss: 1.0528 | Val Acc: 0.4767\n‚úÖ Validation loss improved ‚Äî model saved.\n--------------------------------------------------\n","output_type":"stream"},{"name":"stderr","text":"Train Epoch 3: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 198/198 [00:44<00:00,  4.41it/s]\nValidation Epoch 3: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 29/29 [00:01<00:00, 17.22it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch [3/20]\nTrain Loss: 1.0295 | Train Acc: 0.4924\nVal Loss: 1.0490 | Val Acc: 0.4745\n‚úÖ Validation loss improved ‚Äî model saved.\n--------------------------------------------------\n","output_type":"stream"},{"name":"stderr","text":"Train Epoch 4: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 198/198 [00:44<00:00,  4.40it/s]\nValidation Epoch 4: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 29/29 [00:01<00:00, 17.25it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch [4/20]\nTrain Loss: 1.0218 | Train Acc: 0.4952\nVal Loss: 1.0075 | Val Acc: 0.4900\n‚úÖ Validation loss improved ‚Äî model saved.\n--------------------------------------------------\n","output_type":"stream"},{"name":"stderr","text":"Train Epoch 5: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 198/198 [00:44<00:00,  4.41it/s]\nValidation Epoch 5: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 29/29 [00:01<00:00, 17.27it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch [5/20]\nTrain Loss: 1.0256 | Train Acc: 0.4366\nVal Loss: 1.0102 | Val Acc: 0.4922\n‚è∞ No improvement ‚Äî patience 1/5\n--------------------------------------------------\n","output_type":"stream"},{"name":"stderr","text":"Train Epoch 6: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 198/198 [00:44<00:00,  4.41it/s]\nValidation Epoch 6: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 29/29 [00:01<00:00, 17.28it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch [6/20]\nTrain Loss: 0.9748 | Train Acc: 0.5215\nVal Loss: 0.9837 | Val Acc: 0.5543\n‚úÖ Validation loss improved ‚Äî model saved.\n--------------------------------------------------\n","output_type":"stream"},{"name":"stderr","text":"Train Epoch 7: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 198/198 [00:44<00:00,  4.41it/s]\nValidation Epoch 7: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 29/29 [00:01<00:00, 17.11it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch [7/20]\nTrain Loss: 0.9242 | Train Acc: 0.5951\nVal Loss: 0.9272 | Val Acc: 0.6275\n‚úÖ Validation loss improved ‚Äî model saved.\n--------------------------------------------------\n","output_type":"stream"},{"name":"stderr","text":"Train Epoch 8: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 198/198 [00:44<00:00,  4.40it/s]\nValidation Epoch 8: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 29/29 [00:01<00:00, 16.92it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch [8/20]\nTrain Loss: 0.8316 | Train Acc: 0.7180\nVal Loss: 0.8170 | Val Acc: 0.7228\n‚úÖ Validation loss improved ‚Äî model saved.\n--------------------------------------------------\n","output_type":"stream"},{"name":"stderr","text":"Train Epoch 9: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 198/198 [00:45<00:00,  4.39it/s]\nValidation Epoch 9: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 29/29 [00:01<00:00, 17.10it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch [9/20]\nTrain Loss: 0.7292 | Train Acc: 0.7877\nVal Loss: 0.8092 | Val Acc: 0.7051\n‚úÖ Validation loss improved ‚Äî model saved.\n--------------------------------------------------\n","output_type":"stream"},{"name":"stderr","text":"Train Epoch 10: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 198/198 [00:45<00:00,  4.39it/s]\nValidation Epoch 10: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 29/29 [00:01<00:00, 17.06it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch [10/20]\nTrain Loss: 0.6208 | Train Acc: 0.8397\nVal Loss: 0.7726 | Val Acc: 0.7118\n‚úÖ Validation loss improved ‚Äî model saved.\n--------------------------------------------------\n","output_type":"stream"},{"name":"stderr","text":"Train Epoch 11: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 198/198 [00:45<00:00,  4.39it/s]\nValidation Epoch 11: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 29/29 [00:01<00:00, 17.17it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch [11/20]\nTrain Loss: 0.5388 | Train Acc: 0.8701\nVal Loss: 0.8312 | Val Acc: 0.7095\n‚è∞ No improvement ‚Äî patience 1/5\n--------------------------------------------------\n","output_type":"stream"},{"name":"stderr","text":"Train Epoch 12: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 198/198 [00:45<00:00,  4.40it/s]\nValidation Epoch 12: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 29/29 [00:01<00:00, 17.18it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch [12/20]\nTrain Loss: 0.4623 | Train Acc: 0.8939\nVal Loss: 0.8141 | Val Acc: 0.7118\n‚è∞ No improvement ‚Äî patience 2/5\n--------------------------------------------------\n","output_type":"stream"},{"name":"stderr","text":"Train Epoch 13: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 198/198 [00:45<00:00,  4.40it/s]\nValidation Epoch 13: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 29/29 [00:01<00:00, 17.17it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch [13/20]\nTrain Loss: 0.3789 | Train Acc: 0.9179\nVal Loss: 0.7562 | Val Acc: 0.7384\n‚úÖ Validation loss improved ‚Äî model saved.\n--------------------------------------------------\n","output_type":"stream"},{"name":"stderr","text":"Train Epoch 14: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 198/198 [00:45<00:00,  4.39it/s]\nValidation Epoch 14: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 29/29 [00:01<00:00, 17.15it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch [14/20]\nTrain Loss: 0.3180 | Train Acc: 0.9306\nVal Loss: 0.8397 | Val Acc: 0.6940\n‚è∞ No improvement ‚Äî patience 1/5\n--------------------------------------------------\n","output_type":"stream"},{"name":"stderr","text":"Train Epoch 15: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 198/198 [00:45<00:00,  4.40it/s]\nValidation Epoch 15: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 29/29 [00:01<00:00, 17.02it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch [15/20]\nTrain Loss: 0.2788 | Train Acc: 0.9414\nVal Loss: 0.8670 | Val Acc: 0.7450\n‚è∞ No improvement ‚Äî patience 2/5\n--------------------------------------------------\n","output_type":"stream"},{"name":"stderr","text":"Train Epoch 16: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 198/198 [00:45<00:00,  4.39it/s]\nValidation Epoch 16: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 29/29 [00:01<00:00, 17.04it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch [16/20]\nTrain Loss: 0.2228 | Train Acc: 0.9569\nVal Loss: 0.8404 | Val Acc: 0.7361\n‚è∞ No improvement ‚Äî patience 3/5\n--------------------------------------------------\n","output_type":"stream"},{"name":"stderr","text":"Train Epoch 17: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 198/198 [00:45<00:00,  4.39it/s]\nValidation Epoch 17: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 29/29 [00:01<00:00, 17.06it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch [17/20]\nTrain Loss: 0.1906 | Train Acc: 0.9642\nVal Loss: 0.9131 | Val Acc: 0.7361\n‚è∞ No improvement ‚Äî patience 4/5\n--------------------------------------------------\n","output_type":"stream"},{"name":"stderr","text":"Train Epoch 18: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 198/198 [00:45<00:00,  4.39it/s]\nValidation Epoch 18: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 29/29 [00:01<00:00, 17.03it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch [18/20]\nTrain Loss: 0.1740 | Train Acc: 0.9693\nVal Loss: 0.9282 | Val Acc: 0.7450\n‚è∞ No improvement ‚Äî patience 5/5\nüõë Early stopping triggered at epoch 18\n\nüîç Loading best model for final evaluation...\n","output_type":"stream"},{"name":"stderr","text":"Final Test Evaluation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 57/57 [00:03<00:00, 16.68it/s]","output_type":"stream"},{"name":"stdout","text":"\nüìä FINAL TEST RESULTS (TEXT-ONLY WITH MuRIL):\n============================================================\nTest Accuracy: 0.7694\nTest Precision (Weighted): 0.7762\nTest Recall (Weighted): 0.7694\nTest F1-Score (Weighted): 0.7710\nTest Loss: 0.7081\n\nConfusion Matrix:\n[[311  68  23]\n [ 32 286  35]\n [ 17  33  97]]\n\nüìã PER-CLASS METRICS:\n========================================\nClass 0:\n  Precision: 0.8639\n  Recall: 0.7736\n  F1-Score: 0.8163\n  Support: 402\n\nClass 1:\n  Precision: 0.7390\n  Recall: 0.8102\n  F1-Score: 0.7730\n  Support: 353\n\nClass 2:\n  Precision: 0.6258\n  Recall: 0.6599\n  F1-Score: 0.6424\n  Support: 147\n\nTotal samples: 902\nDataset size - Train: 3156, Val: 451, Test: 902\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":1}]}
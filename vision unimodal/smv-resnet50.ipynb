{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1cb2c1e0",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-07-07T08:19:51.183245Z",
     "iopub.status.busy": "2025-07-07T08:19:51.182953Z",
     "iopub.status.idle": "2025-07-07T08:29:27.608393Z",
     "shell.execute_reply": "2025-07-07T08:29:27.607148Z"
    },
    "papermill": {
     "duration": 576.430449,
     "end_time": "2025-07-07T08:29:27.609745",
     "exception": false,
     "start_time": "2025-07-07T08:19:51.179296",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train samples: 3156\n",
      "Validation samples: 451\n",
      "Test samples: 902\n",
      "Using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Downloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 97.8M/97.8M [00:00<00:00, 199MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total parameters: 24,558,659\n",
      "Trainable parameters: 24,558,659\n",
      "Class distribution: [1404, 1237, 515]\n",
      "Class weights: [2.247863247863248, 2.551333872271625, 6.128155339805825]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch 1: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 198/198 [01:10<00:00,  2.80it/s]\n",
      "Validation Epoch 1: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 29/29 [00:08<00:00,  3.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/25]\n",
      "Train Loss: 0.9921 | Train Acc: 0.5086\n",
      "Val Loss: 0.9573 | Val Acc: 0.5632\n",
      "Learning Rate: 0.000100\n",
      "--------------------------------------------------\n",
      "‚úÖ Validation loss improved ‚Äî model saved.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch 2: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 198/198 [00:48<00:00,  4.04it/s]\n",
      "Validation Epoch 2: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 29/29 [00:06<00:00,  4.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/25]\n",
      "Train Loss: 0.9100 | Train Acc: 0.5688\n",
      "Val Loss: 0.9330 | Val Acc: 0.6120\n",
      "Learning Rate: 0.000100\n",
      "--------------------------------------------------\n",
      "‚úÖ Validation loss improved ‚Äî model saved.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch 3: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 198/198 [00:48<00:00,  4.06it/s]\n",
      "Validation Epoch 3: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 29/29 [00:05<00:00,  4.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/25]\n",
      "Train Loss: 0.8823 | Train Acc: 0.6052\n",
      "Val Loss: 0.8660 | Val Acc: 0.6142\n",
      "Learning Rate: 0.000100\n",
      "--------------------------------------------------\n",
      "‚úÖ Validation loss improved ‚Äî model saved.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch 4: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 198/198 [00:47<00:00,  4.15it/s]\n",
      "Validation Epoch 4: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 29/29 [00:06<00:00,  4.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/25]\n",
      "Train Loss: 0.8435 | Train Acc: 0.6214\n",
      "Val Loss: 0.8641 | Val Acc: 0.6009\n",
      "Learning Rate: 0.000100\n",
      "--------------------------------------------------\n",
      "‚úÖ Validation loss improved ‚Äî model saved.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch 5: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 198/198 [00:49<00:00,  3.99it/s]\n",
      "Validation Epoch 5: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 29/29 [00:06<00:00,  4.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/25]\n",
      "Train Loss: 0.8185 | Train Acc: 0.6233\n",
      "Val Loss: 0.9840 | Val Acc: 0.5565\n",
      "Learning Rate: 0.000050\n",
      "--------------------------------------------------\n",
      "‚è∞ No improvement ‚Äî patience 1/5\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch 6: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 198/198 [00:49<00:00,  4.04it/s]\n",
      "Validation Epoch 6: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 29/29 [00:06<00:00,  4.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/25]\n",
      "Train Loss: 0.7321 | Train Acc: 0.6629\n",
      "Val Loss: 0.9056 | Val Acc: 0.6341\n",
      "Learning Rate: 0.000050\n",
      "--------------------------------------------------\n",
      "‚è∞ No improvement ‚Äî patience 2/5\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch 7: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 198/198 [00:49<00:00,  4.03it/s]\n",
      "Validation Epoch 7: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 29/29 [00:06<00:00,  4.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/25]\n",
      "Train Loss: 0.6729 | Train Acc: 0.6926\n",
      "Val Loss: 0.9438 | Val Acc: 0.6297\n",
      "Learning Rate: 0.000050\n",
      "--------------------------------------------------\n",
      "‚è∞ No improvement ‚Äî patience 3/5\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch 8: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 198/198 [00:48<00:00,  4.04it/s]\n",
      "Validation Epoch 8: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 29/29 [00:06<00:00,  4.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/25]\n",
      "Train Loss: 0.6051 | Train Acc: 0.7357\n",
      "Val Loss: 1.1123 | Val Acc: 0.5876\n",
      "Learning Rate: 0.000050\n",
      "--------------------------------------------------\n",
      "‚è∞ No improvement ‚Äî patience 4/5\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch 9: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 198/198 [00:48<00:00,  4.07it/s]\n",
      "Validation Epoch 9: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 29/29 [00:06<00:00,  4.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/25]\n",
      "Train Loss: 0.5727 | Train Acc: 0.7433\n",
      "Val Loss: 1.1651 | Val Acc: 0.6164\n",
      "Learning Rate: 0.000050\n",
      "--------------------------------------------------\n",
      "‚è∞ No improvement ‚Äî patience 5/5\n",
      "üõë Early stopping triggered at epoch 9\n",
      "\n",
      "üîç Loading best model for final evaluation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Final Test Evaluation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 57/57 [00:15<00:00,  3.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "üìä FINAL TEST RESULTS - VISION ONLY (ResNet50)\n",
      "============================================================\n",
      "Test Accuracy: 0.6020\n",
      "Test Precision: 0.6700\n",
      "Test Recall: 0.6020\n",
      "Test F1-Score: 0.6131\n",
      "Test Loss: 0.8156\n",
      "\n",
      "Best Validation Accuracy: 0.6009\n",
      "Best Validation Loss: 0.8641\n",
      "\n",
      "Confusion Matrix:\n",
      "Predicted ->\n",
      "   0   1   2\n",
      "0: [216 124  62]\n",
      "1: [ 30 227  96]\n",
      "2: [  8  39 100]\n",
      "\n",
      "üìà Class-wise Metrics:\n",
      "Class 0: Precision=0.8504, Recall=0.5373, F1=0.6585, Support=402\n",
      "Class 1: Precision=0.5821, Recall=0.6431, F1=0.6110, Support=353\n",
      "Class 2: Precision=0.3876, Recall=0.6803, F1=0.4938, Support=147\n",
      "\n",
      "üéØ Summary:\n",
      "Vision-only model (ResNet50) achieved 0.6020 accuracy on test set\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# ================================================\n",
    "# ‚úÖ 1Ô∏è‚É£ LIBRARIES & SETUP\n",
    "# ================================================\n",
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "from torch.optim import AdamW\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, confusion_matrix\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models\n",
    "\n",
    "# ================================================\n",
    "# ‚úÖ 2Ô∏è‚É£ PATHS\n",
    "# ================================================\n",
    "image_dir = \"/kaggle/input/basem/images\"\n",
    "input_csv = \"/kaggle/input/basem/dataset.csv\"\n",
    "\n",
    "# ================================================\n",
    "# ‚úÖ 3Ô∏è‚É£ LOAD & PREPROCESS CSV\n",
    "# ================================================\n",
    "df = pd.read_csv(input_csv)\n",
    "\n",
    "existing_data = []\n",
    "for _, row in df.iterrows():\n",
    "    image_filename = row['image_path']\n",
    "    full_image_path = os.path.join(image_dir, image_filename)\n",
    "    if os.path.exists(full_image_path):\n",
    "        label_converted = row['label 2'] - 1\n",
    "        existing_data.append({\n",
    "            'Image_path': full_image_path,\n",
    "            'Label_Sentiment': label_converted\n",
    "        })\n",
    "\n",
    "processed_df = pd.DataFrame(existing_data)\n",
    "\n",
    "# ================================================\n",
    "# ‚úÖ 4Ô∏è‚É£ TRAIN/VAL/TEST SPLIT\n",
    "# ================================================\n",
    "train_df, temp_df = train_test_split(processed_df, test_size=0.3, stratify=processed_df['Label_Sentiment'], random_state=42)\n",
    "test_df, val_df = train_test_split(temp_df, test_size=1/3, stratify=temp_df['Label_Sentiment'], random_state=42)\n",
    "\n",
    "for df_name, df_ in [('train', train_df), ('test', test_df), ('val', val_df)]:\n",
    "    df_['label'] = df_['Label_Sentiment']\n",
    "    df_.to_csv(f'/kaggle/working/{df_name}_vision_only.csv', index=False)\n",
    "\n",
    "print(f\"Train samples: {len(train_df)}\")\n",
    "print(f\"Validation samples: {len(val_df)}\")\n",
    "print(f\"Test samples: {len(test_df)}\")\n",
    "\n",
    "# ================================================\n",
    "# ‚úÖ 5Ô∏è‚É£ DEVICE SETUP\n",
    "# ================================================\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# ================================================\n",
    "# ‚úÖ 6Ô∏è‚É£ IMAGE TRANSFORMS\n",
    "# ================================================\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),\n",
    "    transforms.RandomCrop(224),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.RandomRotation(degrees=10),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "val_test_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# ================================================\n",
    "# ‚úÖ 7Ô∏è‚É£ DATASET CLASS\n",
    "# ================================================\n",
    "class VisionOnlyDataset(Dataset):\n",
    "    def __init__(self, df, transform=None):\n",
    "        self.df = df\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        image_path = row['Image_path']\n",
    "        label = row['label']\n",
    "        \n",
    "        try:\n",
    "            image = Image.open(image_path).convert('RGB')\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading image {image_path}: {e}\")\n",
    "            # Create a black image as fallback\n",
    "            image = Image.new('RGB', (224, 224), color='black')\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        return image, label\n",
    "\n",
    "# ================================================\n",
    "# ‚úÖ 8Ô∏è‚É£ DATALOADERS\n",
    "# ================================================\n",
    "batch_size = 16\n",
    "\n",
    "train_dataset = VisionOnlyDataset(train_df, transform=train_transform)\n",
    "val_dataset = VisionOnlyDataset(val_df, transform=val_test_transform)\n",
    "test_dataset = VisionOnlyDataset(test_df, transform=val_test_transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
    "\n",
    "# ================================================\n",
    "# ‚úÖ 9Ô∏è‚É£ RESNET50 MODEL\n",
    "# ================================================\n",
    "class ResNet50Classifier(nn.Module):\n",
    "    def __init__(self, num_classes=3, dropout=0.5):\n",
    "        super(ResNet50Classifier, self).__init__()\n",
    "        # Load pre-trained ResNet50\n",
    "        self.resnet50 = models.resnet50(pretrained=True)\n",
    "        \n",
    "        # Freeze early layers (optional - uncomment to freeze)\n",
    "        # for param in list(self.resnet50.parameters())[:-20]:\n",
    "        #     param.requires_grad = False\n",
    "        \n",
    "        # Get the number of features from the last layer\n",
    "        num_features = self.resnet50.fc.in_features\n",
    "        \n",
    "        # Replace the classifier\n",
    "        self.resnet50.fc = nn.Sequential(\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(num_features, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(512, num_classes)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.resnet50(x)\n",
    "\n",
    "# ================================================\n",
    "# ‚úÖ üîü MODEL INITIALIZATION\n",
    "# ================================================\n",
    "model = ResNet50Classifier(num_classes=3, dropout=0.5).to(device)\n",
    "\n",
    "# Print model info\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"Total parameters: {total_params:,}\")\n",
    "print(f\"Trainable parameters: {trainable_params:,}\")\n",
    "\n",
    "# ================================================\n",
    "# ‚úÖ 1Ô∏è‚É£1Ô∏è‚É£ LOSS & OPTIMIZER\n",
    "# ================================================\n",
    "# Calculate class weights for balanced training\n",
    "class_weights = train_df['label'].value_counts().sort_index().tolist()\n",
    "total = sum(class_weights)\n",
    "weights = [total / c for c in class_weights]\n",
    "print(f\"Class distribution: {class_weights}\")\n",
    "print(f\"Class weights: {weights}\")\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(weight=torch.FloatTensor(weights).to(device))\n",
    "optimizer = AdamW(model.parameters(), lr=1e-4, weight_decay=1e-4)\n",
    "\n",
    "# Learning rate scheduler\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.5)\n",
    "\n",
    "# ================================================\n",
    "# ‚úÖ 1Ô∏è‚É£2Ô∏è‚É£ TRAINING LOOP\n",
    "# ================================================\n",
    "num_epochs = 25\n",
    "patience = 5\n",
    "patience_counter = 0\n",
    "best_val_loss = float('inf')\n",
    "best_val_acc = 0.0\n",
    "\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "val_accuracies = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    # ============================================================\n",
    "    # TRAINING PHASE\n",
    "    # ============================================================\n",
    "    model.train()\n",
    "    total_train_loss = 0\n",
    "    train_correct = 0\n",
    "    train_total = 0\n",
    "\n",
    "    for images, labels in tqdm(train_loader, desc=f\"Train Epoch {epoch+1}\"):\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Backward pass\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_train_loss += loss.item()\n",
    "        \n",
    "        # Calculate training accuracy\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        train_total += labels.size(0)\n",
    "        train_correct += (predicted == labels).sum().item()\n",
    "\n",
    "    avg_train_loss = total_train_loss / len(train_loader)\n",
    "    train_accuracy = train_correct / train_total\n",
    "    \n",
    "    # ============================================================\n",
    "    # VALIDATION PHASE\n",
    "    # ============================================================\n",
    "    model.eval()\n",
    "    total_val_loss = 0\n",
    "    val_predictions = []\n",
    "    val_labels_list = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in tqdm(val_loader, desc=f\"Validation Epoch {epoch+1}\"):\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            total_val_loss += loss.item()\n",
    "            \n",
    "            # Store predictions for metrics\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            val_predictions.extend(predicted.cpu().numpy())\n",
    "            val_labels_list.extend(labels.cpu().numpy())\n",
    "\n",
    "    avg_val_loss = total_val_loss / len(val_loader)\n",
    "    val_accuracy = accuracy_score(val_labels_list, val_predictions)\n",
    "    \n",
    "    # Store metrics\n",
    "    train_losses.append(avg_train_loss)\n",
    "    val_losses.append(avg_val_loss)\n",
    "    val_accuracies.append(val_accuracy)\n",
    "    \n",
    "    # Update learning rate\n",
    "    scheduler.step()\n",
    "    current_lr = optimizer.param_groups[0]['lr']\n",
    "    \n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}]\")\n",
    "    print(f\"Train Loss: {avg_train_loss:.4f} | Train Acc: {train_accuracy:.4f}\")\n",
    "    print(f\"Val Loss: {avg_val_loss:.4f} | Val Acc: {val_accuracy:.4f}\")\n",
    "    print(f\"Learning Rate: {current_lr:.6f}\")\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "    # ============================================================\n",
    "    # EARLY STOPPING CHECK\n",
    "    # ============================================================\n",
    "    if avg_val_loss < best_val_loss:\n",
    "        best_val_loss = avg_val_loss\n",
    "        best_val_acc = val_accuracy\n",
    "        patience_counter = 0\n",
    "        torch.save(model.state_dict(), \"best_resnet50_model.pt\")\n",
    "        print(\"‚úÖ Validation loss improved ‚Äî model saved.\")\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "        print(f\"‚è∞ No improvement ‚Äî patience {patience_counter}/{patience}\")\n",
    "\n",
    "        if patience_counter >= patience:\n",
    "            print(f\"üõë Early stopping triggered at epoch {epoch+1}\")\n",
    "            break\n",
    "    \n",
    "    print()\n",
    "\n",
    "# ================================================\n",
    "# ‚úÖ 1Ô∏è‚É£3Ô∏è‚É£ FINAL TEST EVALUATION\n",
    "# ================================================\n",
    "print(\"\\nüîç Loading best model for final evaluation...\")\n",
    "model.load_state_dict(torch.load(\"best_resnet50_model.pt\"))\n",
    "model.eval()\n",
    "\n",
    "test_predictions = []\n",
    "test_labels_list = []\n",
    "total_test_loss = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in tqdm(test_loader, desc=\"Final Test Evaluation\"):\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        total_test_loss += loss.item()\n",
    "        \n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        test_predictions.extend(predicted.cpu().numpy())\n",
    "        test_labels_list.extend(labels.cpu().numpy())\n",
    "\n",
    "# Calculate final metrics\n",
    "test_accuracy = accuracy_score(test_labels_list, test_predictions)\n",
    "precision, recall, f1, _ = precision_recall_fscore_support(test_labels_list, test_predictions, average='weighted')\n",
    "cm = confusion_matrix(test_labels_list, test_predictions)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üìä FINAL TEST RESULTS - VISION ONLY (ResNet50)\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Test Accuracy: {test_accuracy:.4f}\")\n",
    "print(f\"Test Precision: {precision:.4f}\")\n",
    "print(f\"Test Recall: {recall:.4f}\")\n",
    "print(f\"Test F1-Score: {f1:.4f}\")\n",
    "print(f\"Test Loss: {total_test_loss/len(test_loader):.4f}\")\n",
    "print(f\"\\nBest Validation Accuracy: {best_val_acc:.4f}\")\n",
    "print(f\"Best Validation Loss: {best_val_loss:.4f}\")\n",
    "\n",
    "print(f\"\\nConfusion Matrix:\")\n",
    "print(\"Predicted ->\")\n",
    "print(\"   0   1   2\")\n",
    "for i, row in enumerate(cm):\n",
    "    print(f\"{i}: {row}\")\n",
    "\n",
    "# Class-wise metrics\n",
    "precision_class, recall_class, f1_class, support = precision_recall_fscore_support(test_labels_list, test_predictions, average=None)\n",
    "print(f\"\\nüìà Class-wise Metrics:\")\n",
    "for i in range(len(precision_class)):\n",
    "    print(f\"Class {i}: Precision={precision_class[i]:.4f}, Recall={recall_class[i]:.4f}, F1={f1_class[i]:.4f}, Support={support[i]}\")\n",
    "\n",
    "print(\"\\nüéØ Summary:\")\n",
    "print(f\"Vision-only model (ResNet50) achieved {test_accuracy:.4f} accuracy on test set\")\n",
    "print(\"=\"*60)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 7789382,
     "sourceId": 12355137,
     "sourceType": "datasetVersion"
    }
   ],
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 583.503193,
   "end_time": "2025-07-07T08:29:30.598431",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-07-07T08:19:47.095238",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

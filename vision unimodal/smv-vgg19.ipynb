{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cbec1bd4",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-07-07T08:58:59.036165Z",
     "iopub.status.busy": "2025-07-07T08:58:59.035929Z",
     "iopub.status.idle": "2025-07-07T09:03:25.391137Z",
     "shell.execute_reply": "2025-07-07T09:03:25.389889Z"
    },
    "papermill": {
     "duration": 266.359811,
     "end_time": "2025-07-07T09:03:25.392382",
     "exception": false,
     "start_time": "2025-07-07T08:58:59.032571",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG19_Weights.IMAGENET1K_V1`. You can also use `weights=VGG19_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Downloading: \"https://download.pytorch.org/models/vgg19-dcbb9e9d.pth\" to /root/.cache/torch/hub/checkpoints/vgg19-dcbb9e9d.pth\n",
      "100%|██████████| 548M/548M [00:02<00:00, 197MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n",
      "Train samples: 3156\n",
      "Validation samples: 451\n",
      "Test samples: 902\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch 1: 100%|██████████| 99/99 [00:41<00:00,  2.37it/s]\n",
      "Validation Epoch 1: 100%|██████████| 15/15 [00:05<00:00,  2.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20]\n",
      "Train Loss: 0.9941 | Train Acc: 0.5098\n",
      "Val Loss: 0.9543 | Val Acc: 0.5233\n",
      "Learning Rate: 0.000010\n",
      "--------------------------------------------------\n",
      "✅ Validation loss improved — model saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch 2: 100%|██████████| 99/99 [00:38<00:00,  2.58it/s]\n",
      "Validation Epoch 2: 100%|██████████| 15/15 [00:05<00:00,  2.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/20]\n",
      "Train Loss: 0.8701 | Train Acc: 0.5852\n",
      "Val Loss: 0.8704 | Val Acc: 0.6031\n",
      "Learning Rate: 0.000010\n",
      "--------------------------------------------------\n",
      "✅ Validation loss improved — model saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch 3: 100%|██████████| 99/99 [00:38<00:00,  2.55it/s]\n",
      "Validation Epoch 3: 100%|██████████| 15/15 [00:05<00:00,  2.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/20]\n",
      "Train Loss: 0.7867 | Train Acc: 0.6397\n",
      "Val Loss: 0.9945 | Val Acc: 0.6186\n",
      "Learning Rate: 0.000010\n",
      "--------------------------------------------------\n",
      "⏰ No improvement — patience 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch 4: 100%|██████████| 99/99 [00:38<00:00,  2.60it/s]\n",
      "Validation Epoch 4: 100%|██████████| 15/15 [00:05<00:00,  2.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/20]\n",
      "Train Loss: 0.6789 | Train Acc: 0.6876\n",
      "Val Loss: 1.0390 | Val Acc: 0.6164\n",
      "Learning Rate: 0.000010\n",
      "--------------------------------------------------\n",
      "⏰ No improvement — patience 2/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch 5: 100%|██████████| 99/99 [00:38<00:00,  2.59it/s]\n",
      "Validation Epoch 5: 100%|██████████| 15/15 [00:05<00:00,  2.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/20]\n",
      "Train Loss: 0.5851 | Train Acc: 0.7376\n",
      "Val Loss: 1.2908 | Val Acc: 0.6208\n",
      "Learning Rate: 0.000010\n",
      "--------------------------------------------------\n",
      "⏰ No improvement — patience 3/3\n",
      "🛑 Early stopping triggered at epoch 5\n",
      "\n",
      "🔍 Loading best model for final evaluation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Final Test Evaluation: 100%|██████████| 29/29 [00:10<00:00,  2.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📊 FINAL TEST RESULTS (Vision-Only VGG19):\n",
      "==================================================\n",
      "Test Accuracy: 0.6330\n",
      "Test Precision: 0.6878\n",
      "Test Recall: 0.6330\n",
      "Test F1-Score: 0.6355\n",
      "Test Loss: 0.8745\n",
      "\n",
      "Confusion Matrix:\n",
      "[[212 147  43]\n",
      " [ 27 272  54]\n",
      " [  6  54  87]]\n",
      "\n",
      "📋 Detailed Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Class 0       0.87      0.53      0.66       402\n",
      "     Class 1       0.58      0.77      0.66       353\n",
      "     Class 2       0.47      0.59      0.53       147\n",
      "\n",
      "    accuracy                           0.63       902\n",
      "   macro avg       0.64      0.63      0.61       902\n",
      "weighted avg       0.69      0.63      0.64       902\n",
      "\n",
      "\n",
      "✅ Results saved to '/kaggle/working/vgg19_results.json'\n",
      "✅ Best model saved as 'best_vgg19_model.pt'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# ================================================\n",
    "# ✅ 1️⃣ LIBRARIES & SETUP\n",
    "# ================================================\n",
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "from torch.optim import AdamW\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, confusion_matrix\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models\n",
    "\n",
    "# ================================================\n",
    "# ✅ 2️⃣ PATHS\n",
    "# ================================================\n",
    "image_dir = \"/kaggle/input/basem/images\"\n",
    "input_csv = \"/kaggle/input/basem/dataset.csv\"\n",
    "\n",
    "# ================================================\n",
    "# ✅ 3️⃣ LOAD & PREPROCESS CSV\n",
    "# ================================================\n",
    "df = pd.read_csv(input_csv)\n",
    "\n",
    "existing_data = []\n",
    "for _, row in df.iterrows():\n",
    "    image_filename = row['image_path']\n",
    "    full_image_path = os.path.join(image_dir, image_filename)\n",
    "    if os.path.exists(full_image_path):\n",
    "        label_converted = row['label 2'] - 1\n",
    "        existing_data.append({\n",
    "            'Image_path': full_image_path,\n",
    "            'Label_Sentiment': label_converted\n",
    "        })\n",
    "\n",
    "processed_df = pd.DataFrame(existing_data)\n",
    "\n",
    "# ================================================\n",
    "# ✅ 4️⃣ DATA SPLITTING\n",
    "# ================================================\n",
    "train_df, temp_df = train_test_split(processed_df, test_size=0.3, stratify=processed_df['Label_Sentiment'], random_state=42)\n",
    "test_df, val_df = train_test_split(temp_df, test_size=1/3, stratify=temp_df['Label_Sentiment'], random_state=42)\n",
    "\n",
    "for df_name, df_ in [('train', train_df), ('test', test_df), ('val', val_df)]:\n",
    "    df_['label'] = df_['Label_Sentiment']\n",
    "    df_.to_csv(f'/kaggle/working/{df_name}_cleaned.csv', index=False)\n",
    "\n",
    "# ================================================\n",
    "# ✅ 5️⃣ DEVICE SETUP\n",
    "# ================================================\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# ================================================\n",
    "# ✅ 6️⃣ IMAGE TRANSFORMS\n",
    "# ================================================\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "val_test_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# ================================================\n",
    "# ✅ 7️⃣ VISION DATASET\n",
    "# ================================================\n",
    "class VisionDataset(Dataset):\n",
    "    def __init__(self, df, transform=None):\n",
    "        self.df = df\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        image = Image.open(row['Image_path']).convert('RGB')\n",
    "        label = row['label']\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        return image, label\n",
    "\n",
    "# ================================================\n",
    "# ✅ 8️⃣ DATALOADERS\n",
    "# ================================================\n",
    "batch_size = 32\n",
    "\n",
    "train_dataset = VisionDataset(train_df, transform=train_transform)\n",
    "val_dataset = VisionDataset(val_df, transform=val_test_transform)\n",
    "test_dataset = VisionDataset(test_df, transform=val_test_transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=4)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=4)\n",
    "\n",
    "# ================================================\n",
    "# ✅ 9️⃣ VGG19 MODEL\n",
    "# ================================================\n",
    "class VGG19Classifier(nn.Module):\n",
    "    def __init__(self, num_classes=3, dropout_rate=0.5):\n",
    "        super(VGG19Classifier, self).__init__()\n",
    "        \n",
    "        # Load pre-trained VGG19\n",
    "        self.vgg19 = models.vgg19(pretrained=True)\n",
    "        \n",
    "        # Freeze early layers (optional - you can experiment with this)\n",
    "        for param in self.vgg19.features[:20].parameters():\n",
    "            param.requires_grad = False\n",
    "        \n",
    "        # Replace the classifier\n",
    "        self.vgg19.classifier = nn.Sequential(\n",
    "            nn.Linear(25088, 4096),\n",
    "            nn.ReLU(True),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(4096, 2048),\n",
    "            nn.ReLU(True),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(2048, 1024),\n",
    "            nn.ReLU(True),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(1024, num_classes)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.vgg19(x)\n",
    "\n",
    "# ================================================\n",
    "# ✅ 🔟 MODEL INITIALIZATION\n",
    "# ================================================\n",
    "model = VGG19Classifier(num_classes=3, dropout_rate=0.5).to(device)\n",
    "\n",
    "# ================================================\n",
    "# ✅ 1️⃣1️⃣ LOSS & OPTIMIZER\n",
    "# ================================================\n",
    "# Calculate class weights for imbalanced dataset\n",
    "class_weights = train_df['label'].value_counts().sort_index().tolist()\n",
    "total = sum(class_weights)\n",
    "weights = [total / c for c in class_weights]\n",
    "criterion = nn.CrossEntropyLoss(weight=torch.FloatTensor(weights).to(device))\n",
    "\n",
    "# Optimizer with different learning rates for different parts\n",
    "optimizer = AdamW([\n",
    "    {'params': model.vgg19.features.parameters(), 'lr': 1e-5},  # Lower LR for pre-trained features\n",
    "    {'params': model.vgg19.classifier.parameters(), 'lr': 1e-4}  # Higher LR for new classifier\n",
    "], weight_decay=1e-4)\n",
    "\n",
    "# Learning rate scheduler\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)\n",
    "\n",
    "# ================================================\n",
    "# ✅ 1️⃣2️⃣ TRAINING LOOP\n",
    "# ================================================\n",
    "num_epochs = 20\n",
    "patience = 3\n",
    "patience_counter = 0\n",
    "best_val_loss = float('inf')\n",
    "\n",
    "print(\"Starting training...\")\n",
    "print(f\"Train samples: {len(train_dataset)}\")\n",
    "print(f\"Validation samples: {len(val_dataset)}\")\n",
    "print(f\"Test samples: {len(test_dataset)}\")\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    # ============================================================\n",
    "    # TRAINING PHASE\n",
    "    # ============================================================\n",
    "    model.train()\n",
    "    total_train_loss = 0\n",
    "    train_predictions = []\n",
    "    train_labels = []\n",
    "\n",
    "    for images, labels in tqdm(train_loader, desc=f\"Train Epoch {epoch+1}\"):\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_train_loss += loss.item()\n",
    "        \n",
    "        # Store predictions for metrics\n",
    "        predictions = torch.argmax(outputs, dim=1)\n",
    "        train_predictions.extend(predictions.cpu().numpy())\n",
    "        train_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    avg_train_loss = total_train_loss / len(train_loader)\n",
    "    train_accuracy = accuracy_score(train_labels, train_predictions)\n",
    "\n",
    "    # ============================================================\n",
    "    # VALIDATION PHASE\n",
    "    # ============================================================\n",
    "    model.eval()\n",
    "    total_val_loss = 0\n",
    "    val_predictions = []\n",
    "    val_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in tqdm(val_loader, desc=f\"Validation Epoch {epoch+1}\"):\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            total_val_loss += loss.item()\n",
    "            \n",
    "            # Store predictions for metrics\n",
    "            predictions = torch.argmax(outputs, dim=1)\n",
    "            val_predictions.extend(predictions.cpu().numpy())\n",
    "            val_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    avg_val_loss = total_val_loss / len(val_loader)\n",
    "    val_accuracy = accuracy_score(val_labels, val_predictions)\n",
    "    \n",
    "    # Update learning rate\n",
    "    scheduler.step()\n",
    "    \n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}]\")\n",
    "    print(f\"Train Loss: {avg_train_loss:.4f} | Train Acc: {train_accuracy:.4f}\")\n",
    "    print(f\"Val Loss: {avg_val_loss:.4f} | Val Acc: {val_accuracy:.4f}\")\n",
    "    print(f\"Learning Rate: {optimizer.param_groups[0]['lr']:.6f}\")\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "    # ============================================================\n",
    "    # EARLY STOPPING CHECK\n",
    "    # ============================================================\n",
    "    if avg_val_loss < best_val_loss:\n",
    "        best_val_loss = avg_val_loss\n",
    "        patience_counter = 0\n",
    "        torch.save(model.state_dict(), \"best_vgg19_model.pt\")\n",
    "        print(\"✅ Validation loss improved — model saved.\")\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "        print(f\"⏰ No improvement — patience {patience_counter}/{patience}\")\n",
    "\n",
    "        if patience_counter >= patience:\n",
    "            print(f\"🛑 Early stopping triggered at epoch {epoch+1}\")\n",
    "            break\n",
    "\n",
    "# ================================================\n",
    "# ✅ 1️⃣3️⃣ FINAL TEST EVALUATION\n",
    "# ================================================\n",
    "print(\"\\n🔍 Loading best model for final evaluation...\")\n",
    "model.load_state_dict(torch.load(\"best_vgg19_model.pt\"))\n",
    "model.eval()\n",
    "\n",
    "test_predictions = []\n",
    "test_labels = []\n",
    "total_test_loss = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in tqdm(test_loader, desc=\"Final Test Evaluation\"):\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        total_test_loss += loss.item()\n",
    "        predictions = torch.argmax(outputs, dim=1)\n",
    "        test_predictions.extend(predictions.cpu().numpy())\n",
    "        test_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "# Calculate final metrics\n",
    "test_accuracy = accuracy_score(test_labels, test_predictions)\n",
    "precision, recall, f1, _ = precision_recall_fscore_support(test_labels, test_predictions, average='weighted')\n",
    "cm = confusion_matrix(test_labels, test_predictions)\n",
    "\n",
    "print(\"\\n📊 FINAL TEST RESULTS (Vision-Only VGG19):\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Test Accuracy: {test_accuracy:.4f}\")\n",
    "print(f\"Test Precision: {precision:.4f}\")\n",
    "print(f\"Test Recall: {recall:.4f}\")\n",
    "print(f\"Test F1-Score: {f1:.4f}\")\n",
    "print(f\"Test Loss: {total_test_loss/len(test_loader):.4f}\")\n",
    "print(f\"\\nConfusion Matrix:\\n{cm}\")\n",
    "\n",
    "# ================================================\n",
    "# ✅ 1️⃣4️⃣ DETAILED CLASSIFICATION REPORT\n",
    "# ================================================\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(\"\\n📋 Detailed Classification Report:\")\n",
    "print(classification_report(test_labels, test_predictions, \n",
    "                          target_names=['Class 0', 'Class 1', 'Class 2']))\n",
    "\n",
    "# ================================================\n",
    "# ✅ 1️⃣5️⃣ SAVE RESULTS\n",
    "# ================================================\n",
    "results_dict = {\n",
    "    'test_accuracy': test_accuracy,\n",
    "    'test_precision': precision,\n",
    "    'test_recall': recall,\n",
    "    'test_f1': f1,\n",
    "    'test_loss': total_test_loss/len(test_loader),\n",
    "    'confusion_matrix': cm.tolist()\n",
    "}\n",
    "\n",
    "import json\n",
    "with open('/kaggle/working/vgg19_results.json', 'w') as f:\n",
    "    json.dump(results_dict, f, indent=2)\n",
    "\n",
    "print(\"\\n✅ Results saved to '/kaggle/working/vgg19_results.json'\")\n",
    "print(\"✅ Best model saved as 'best_vgg19_model.pt'\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 7789382,
     "sourceId": 12355137,
     "sourceType": "datasetVersion"
    }
   ],
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 273.410319,
   "end_time": "2025-07-07T09:03:28.536560",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-07-07T08:58:55.126241",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
